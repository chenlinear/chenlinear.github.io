<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Liste - https://ChenLi2049.github.io"><title>Machine Learning Notes: torch.nn | Chen Li</title><meta name=description content="Chen Li's personal blog"><meta property="og:title" content="Machine Learning Notes: torch.nn"><meta property="og:description" content="(Please refer to Wow It Fits! — Secondhand Machine Learning.)
This is a quick introduction to torch or how to build a neural network without writing the source code. For the purpose of each layer, see torch.nn and Dive into Deep Learning. Basically, after CNN, parts of the picture is highlighted and the number of channels (RGB $\rightarrow$ many more) can be different (see CNN Explainer).
In the following code, first import the required packages:"><meta property="og:type" content="article"><meta property="og:url" content="https://ChenLi2049.github.io/posts/20230614-machine-learning-notes-torch-nn/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-14T00:00:00+00:00"><meta property="article:modified_time" content="2023-06-14T00:00:00+00:00"><meta itemprop=name content="Machine Learning Notes: torch.nn"><meta itemprop=description content="(Please refer to Wow It Fits! — Secondhand Machine Learning.)
This is a quick introduction to torch or how to build a neural network without writing the source code. For the purpose of each layer, see torch.nn and Dive into Deep Learning. Basically, after CNN, parts of the picture is highlighted and the number of channels (RGB $\rightarrow$ many more) can be different (see CNN Explainer).
In the following code, first import the required packages:"><meta itemprop=datePublished content="2023-06-14T00:00:00+00:00"><meta itemprop=dateModified content="2023-06-14T00:00:00+00:00"><meta itemprop=wordCount content="717"><meta itemprop=keywords content="programming,"><link rel=canonical href=https://ChenLi2049.github.io/posts/20230614-machine-learning-notes-torch-nn/><link rel=icon href=https://ChenLi2049.github.io/assets/favicon.ico><link rel=dns-prefetch href=https://www.google-analytics.com><link href=https://www.google-analytics.com rel=preconnect crossorigin><link rel=alternate type=application/atom+xml title="Chen Li" href=https://ChenLi2049.github.io/atom.xml><link rel=alternate type=application/json title="Chen Li" href=https://ChenLi2049.github.io/feed.json><link rel="shortcut icon" type=image/png href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="><style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-align:justify;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:rbg(169,169,169,1);color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5{font-size:20px;font-weight:600;text-align:center}strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a:hover,a.heading-link{text-decoration:none}a,a:visited{color:#008b8b}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:circle}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:90ch;margin:0 auto}header{line-height:1;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:135px;width:135px;position:relative;margin:0 0 0 15px;float:right;border-radius:25%}table{border-collapse:collapse}table th,table td{border:1px solid #bebebe;padding:0 5px}.toc{margin:0 auto;width:100%;padding:0;margin-bottom:10px;background-color:#f9f9f9}</style><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"posts","name":"Machine Learning Notes: torch.nn","headline":"Machine Learning Notes: torch.nn","alternativeHeadline":"","description":"(Please refer to Wow It Fits! — Secondhand Machine Learning.)\nThis is a quick introduction to torch or how to build a neural network without writing the source code. For the purpose of each layer, see torch.nn and Dive into Deep Learning. Basically, after CNN, parts of the picture is highlighted and the number of channels (RGB $\\rightarrow$ many more) can be different (see CNN Explainer).\nIn the following code, first import the required packages:","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/ChenLi2049.github.io\/posts\/20230614-machine-learning-notes-torch-nn\/"},"author":{"@type":"Person","name":"Chen Li"},"creator":{"@type":"Person","name":"Chen Li"},"accountablePerson":{"@type":"Person","name":"Chen Li"},"copyrightHolder":"Chen Li","copyrightYear":"2023","dateCreated":"2023-06-14T00:00:00.00Z","datePublished":"2023-06-14T00:00:00.00Z","dateModified":"2023-06-14T00:00:00.00Z","publisher":{"@type":"Organization","name":"Chen Li","url":"https://ChenLi2049.github.io","logo":{"@type":"ImageObject","url":"https:\/\/ChenLi2049.github.io\/assets\/favicon.ico","width":"32","height":"32"}},"image":"https://ChenLi2049.github.io/assets/favicon.ico","url":"https:\/\/ChenLi2049.github.io\/posts\/20230614-machine-learning-notes-torch-nn\/","wordCount":"717","genre":["programming"],"keywords":["programming"]}</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/katex.min.css><script defer src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/katex.min.js></script>
<script defer src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body><a class=skip-link href=#main>Skip to main</a><main id=main><div class=content><header><p style=padding:0;margin:0><a href=/><b>Chen Li</b>
<span class="text-stone-500 animate-blink"></span></a></p><ul style=padding:0;margin:0><li><a href=/cv/><span>CV</span></a><li><a href=/posts/><span>Posts</span></a><li><a href=/about/><span>About</span></a></li></ul></header><hr class=hr-list style=padding:0;margin:0><section><h2 class=post>Machine Learning Notes: torch.nn</h2><div class=toc><nav id=TableOfContents><ul><li><a href=#nnconv2d>nn.Conv2d</a></li><li><a href=#nnmaxpool2d>nn.MaxPool2d</a></li><li><a href=#nnbatchnorm2d>nn.BatchNorm2d</a></li><li><a href=#nnlinear>nn.Linear</a></li><li><a href=#nndropout>nn.Dropout</a></li><li><a href=#nnrelu-or-frelu>nn.ReLU or F.relu</a></li><li><a href=#nnrnn>nn.RNN</a></li><li><a href=#nnmodule>nn.Module</a></li><li><a href=#nnsequential>nn.Sequential</a></li><li><a href=#the-smallest-framework>The Smallest Framework</a></li></ul></nav></div><p>(Please refer to <a href=https://chenlinear.github.io/posts/20231011-wow-it-fits-secondhand-machine-learning/><em>Wow It Fits! — Secondhand Machine Learning</em></a>.)</p><p>This is a quick introduction to torch or how to build a neural network without writing the source code. For the purpose of each layer, see <a href=https://pytorch.org/docs/stable/nn.html>torch.nn</a> and <a href=https://d2l.ai/><em>Dive into Deep Learning</em></a>. Basically, after CNN, parts of the picture is highlighted and the number of channels (RGB $\rightarrow$ many more) can be different (see <a href=https://poloclub.github.io/cnn-explainer/>CNN Explainer</a>).</p><p>In the following code, first <code>import</code> the required packages:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>torch</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>torch.nn</span> <span style=color:#00a8c8>as</span> <span style=color:#111>nn</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>torch.nn.functional</span> <span style=color:#00a8c8>as</span> <span style=color:#111>F</span>
</span></span></code></pre></div><h2 id=nnconv2d>nn.Conv2d</h2><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randn</span><span style=color:#111>(</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#ae81ff>28</span><span style=color:#111>,</span> <span style=color:#ae81ff>28</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>conv2d</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Conv2d</span><span style=color:#111>(</span><span style=color:#111>in_channels</span><span style=color:#f92672>=</span><span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#111>out_channels</span><span style=color:#f92672>=</span><span style=color:#ae81ff>12</span><span style=color:#111>,</span> <span style=color:#111>kernel_size</span><span style=color:#f92672>=</span><span style=color:#ae81ff>3</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>conv2d</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>will get:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>1, 3, 28, 28<span style=color:#f92672>])</span>
</span></span><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>1, 12, 26, 26<span style=color:#f92672>])</span>
</span></span></code></pre></div><h2 id=nnmaxpool2d>nn.MaxPool2d</h2><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randn</span><span style=color:#111>(</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#ae81ff>28</span><span style=color:#111>,</span> <span style=color:#ae81ff>28</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>pool</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>MaxPool2d</span><span style=color:#111>(</span><span style=color:#111>kernel_size</span><span style=color:#f92672>=</span><span style=color:#ae81ff>2</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>pool</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>will get:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>1, 3, 28, 28<span style=color:#f92672>])</span>
</span></span><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>1, 3, 14, 14<span style=color:#f92672>])</span>
</span></span></code></pre></div><h2 id=nnbatchnorm2d>nn.BatchNorm2d</h2><p>See Fig.2 of <a href=https://arxiv.org/abs/1803.08494>[1803.08494] <em>Group Normalization</em></a>.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>batchnorm</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>BatchNorm2d</span><span style=color:#111>(</span><span style=color:#ae81ff>3</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randn</span><span style=color:#111>(</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#ae81ff>3</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>batchnorm</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>will get:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tensor<span style=color:#f92672>([[[[</span>-2.3440,  0.5965,  1.2750<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.8684,  1.4049, -1.5865<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span> 0.0760,  0.3308,  1.4631<span style=color:#f92672>]]</span>,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>         <span style=color:#f92672>[[</span>-0.7283,  0.6978,  1.1655<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.2090,  1.4090,  1.0433<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.1820,  0.0191,  1.8880<span style=color:#f92672>]]</span>,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>         <span style=color:#f92672>[[</span> 2.5024,  0.5590,  1.6343<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.2351, -0.8212, -1.0195<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.6536,  0.2503,  0.1578<span style=color:#f92672>]]]])</span>
</span></span><span style=display:flex><span>tensor<span style=color:#f92672>([[[[</span>-1.8478,  0.4327,  0.9589<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.7034,  1.0596, -1.2603<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span> 0.0290,  0.2266,  1.1048<span style=color:#f92672>]]</span>,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>         <span style=color:#f92672>[[</span>-1.5610,  0.1576,  0.7212<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.9351,  1.0146,  0.5739<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.9027, -0.6603,  1.5918<span style=color:#f92672>]]</span>,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>         <span style=color:#f92672>[[</span> 2.0339,  0.2682,  1.2452<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.4533, -0.9858, -1.1660<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>          <span style=color:#f92672>[</span>-0.8336, -0.0122, -0.0964<span style=color:#f92672>]]]]</span>, <span style=color:#111>grad_fn</span><span style=color:#f92672>=</span>&lt;NativeBatchNormBackward0&gt;<span style=color:#f92672>)</span>
</span></span></code></pre></div><h2 id=nnlinear>nn.Linear</h2><p>For fully connected layer.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>linear</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Linear</span><span style=color:#111>(</span><span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#ae81ff>12</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randn</span><span style=color:#111>(</span><span style=color:#ae81ff>128</span><span style=color:#111>,</span> <span style=color:#ae81ff>3</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>linear</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>will get:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>128, 12<span style=color:#f92672>])</span>
</span></span></code></pre></div><h2 id=nndropout>nn.Dropout</h2><p>For fully connected layer. Using the samples in the Bernoulli distribution, some elements of the input tensor are randomly zeroed with probability $p$. To use it:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>dropout</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Dropout</span><span style=color:#111>(</span><span style=color:#111>p</span><span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span><span style=color:#111>,</span> <span style=color:#111>inplace</span><span style=color:#f92672>=</span><span style=color:#00a8c8>False</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>dropout</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span></code></pre></div><p><code>x</code> can be a tensor in any shape.</p><h2 id=nnrelu-or-frelu>nn.ReLU or F.relu</h2><p>Activation function, $\text{ReLU}(x)=\max{(0,x)}$, to use it：</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>ReLU</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>or:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>F</span><span style=color:#f92672>.</span><span style=color:#111>relu</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span></code></pre></div><p><code>x</code> can be a tensor in any shape.</p><h2 id=nnrnn>nn.RNN</h2><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>input_size</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span><span style=color:#111>hidden_size</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>20</span>
</span></span><span style=display:flex><span><span style=color:#111>num_layers</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span><span style=color:#111>seq_length</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span><span style=display:flex><span><span style=color:#111>batch_size</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span><span style=color:#111>rnn</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>RNN</span><span style=color:#111>(</span><span style=color:#111>input_size</span><span style=color:#111>,</span> <span style=color:#111>hidden_size</span><span style=color:#111>,</span> <span style=color:#111>num_layers</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>input_data</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randn</span><span style=color:#111>(</span><span style=color:#111>seq_length</span><span style=color:#111>,</span> <span style=color:#111>batch_size</span><span style=color:#111>,</span> <span style=color:#111>input_size</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>output</span><span style=color:#111>,</span> <span style=color:#111>hidden_state</span> <span style=color:#f92672>=</span> <span style=color:#111>rnn</span><span style=color:#111>(</span><span style=color:#111>input_data</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>output</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>will get:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>5, 3, 20<span style=color:#f92672>])</span>
</span></span></code></pre></div><h2 id=nnmodule>nn.Module</h2><p>Construct a block of layers. It could be the entire model or just a block of the entire model or loss function, etc.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#00a8c8>class</span> <span style=color:#75af00>MyBlock</span><span style=color:#111>(</span><span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Module</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>def</span> <span style=color:#111>__init__</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>        <span style=color:#111>super</span><span style=color:#111>()</span><span style=color:#f92672>.</span><span style=color:#111>__init__</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># define every layer</span>
</span></span><span style=display:flex><span>        <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv1</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Conv2d</span><span style=color:#111>(</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#ae81ff>20</span><span style=color:#111>,</span> <span style=color:#ae81ff>5</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv2</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Conv2d</span><span style=color:#111>(</span><span style=color:#ae81ff>20</span><span style=color:#111>,</span> <span style=color:#ae81ff>20</span><span style=color:#111>,</span> <span style=color:#ae81ff>5</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>def</span> <span style=color:#75af00>forward</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#111>,</span> <span style=color:#111>x</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># define forward propagation</span>
</span></span><span style=display:flex><span>        <span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>F</span><span style=color:#f92672>.</span><span style=color:#111>relu</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv1</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>))</span>
</span></span><span style=display:flex><span>        <span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>F</span><span style=color:#f92672>.</span><span style=color:#111>relu</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv2</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>))</span>
</span></span><span style=display:flex><span>        <span style=color:#00a8c8>return</span> <span style=color:#111>x</span>
</span></span></code></pre></div><h2 id=nnsequential>nn.Sequential</h2><p>Compared with <code>nn.Module</code>, <code>nn.Sequential</code> can add the layers more easily and don&rsquo;t have to define forward propagation. This is more useful when building a simple neural network.</p><p>For example, to construct a model with a 2d convolution layer, a ReLU layer and a 2d convolution layer:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>model</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Sequential</span><span style=color:#111>(</span>
</span></span><span style=display:flex><span>    <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Conv2d</span><span style=color:#111>(</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#ae81ff>20</span><span style=color:#111>,</span> <span style=color:#ae81ff>5</span><span style=color:#111>),</span>
</span></span><span style=display:flex><span>    <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>ReLU</span><span style=color:#111>(),</span>
</span></span><span style=display:flex><span>    <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Conv2d</span><span style=color:#111>(</span><span style=color:#ae81ff>20</span><span style=color:#111>,</span> <span style=color:#ae81ff>64</span><span style=color:#111>,</span> <span style=color:#ae81ff>5</span><span style=color:#111>),</span>
</span></span><span style=display:flex><span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randn</span><span style=color:#111>(</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#ae81ff>30</span><span style=color:#111>,</span> <span style=color:#ae81ff>30</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>y</span> <span style=color:#f92672>=</span> <span style=color:#111>model</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>y</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>will get:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>1, 64, 22, 22<span style=color:#f92672>])</span>
</span></span></code></pre></div><h2 id=the-smallest-framework>The Smallest Framework</h2><p>In practice, the whole project often looks like this:</p><pre tabindex=0><code>├── data
│   ├── processed
│   └── raw
├── src
│   ├── __init__.py
│   ├── config.json
│   ├── loss.py
│   ├── models.py
│   └── utils.py
├── LICENSE
├── predict.py
├── prepare_dataset.py
├── README.md
├── requirements.txt
└── train.py
</code></pre><p>But this is just a simple model, so it&rsquo;s just one file.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#00a8c8>class</span> <span style=color:#75af00>MyNetwork</span><span style=color:#111>(</span><span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Module</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>def</span> <span style=color:#111>__init__</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>        <span style=color:#111>super</span><span style=color:#111>()</span><span style=color:#f92672>.</span><span style=color:#111>__init__</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Define every layer</span>
</span></span><span style=display:flex><span>        <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv1</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Conv2d</span><span style=color:#111>(</span><span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#ae81ff>16</span><span style=color:#111>,</span> <span style=color:#111>kernel_size</span><span style=color:#f92672>=</span><span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#111>stride</span><span style=color:#f92672>=</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#111>padding</span><span style=color:#f92672>=</span><span style=color:#ae81ff>1</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv2</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Conv2d</span><span style=color:#111>(</span><span style=color:#ae81ff>16</span><span style=color:#111>,</span> <span style=color:#ae81ff>32</span><span style=color:#111>,</span> <span style=color:#111>kernel_size</span><span style=color:#f92672>=</span><span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#111>stride</span><span style=color:#f92672>=</span><span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#111>padding</span><span style=color:#f92672>=</span><span style=color:#ae81ff>1</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>fc1</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Linear</span><span style=color:#111>(</span><span style=color:#ae81ff>32</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>32</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>32</span><span style=color:#111>,</span> <span style=color:#ae81ff>128</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>fc2</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>Linear</span><span style=color:#111>(</span><span style=color:#ae81ff>128</span><span style=color:#111>,</span> <span style=color:#ae81ff>10</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>def</span> <span style=color:#75af00>forward</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#111>,</span> <span style=color:#111>x</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Define forward propagation</span>
</span></span><span style=display:flex><span>        <span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>F</span><span style=color:#f92672>.</span><span style=color:#111>relu</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv1</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>))</span>
</span></span><span style=display:flex><span>        <span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>F</span><span style=color:#f92672>.</span><span style=color:#111>relu</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>conv2</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>))</span>
</span></span><span style=display:flex><span>        <span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>x</span><span style=color:#f92672>.</span><span style=color:#111>view</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#f92672>.</span><span style=color:#111>size</span><span style=color:#111>(</span><span style=color:#ae81ff>0</span><span style=color:#111>),</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>F</span><span style=color:#f92672>.</span><span style=color:#111>relu</span><span style=color:#111>(</span><span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>fc1</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>))</span>
</span></span><span style=display:flex><span>        <span style=color:#111>x</span> <span style=color:#f92672>=</span> <span style=color:#111>self</span><span style=color:#f92672>.</span><span style=color:#111>fc2</span><span style=color:#111>(</span><span style=color:#111>x</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>        <span style=color:#00a8c8>return</span> <span style=color:#111>x</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>model</span> <span style=color:#f92672>=</span> <span style=color:#111>MyNetwork</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>criterion</span> <span style=color:#f92672>=</span> <span style=color:#111>nn</span><span style=color:#f92672>.</span><span style=color:#111>CrossEntropyLoss</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>optimizer</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>optim</span><span style=color:#f92672>.</span><span style=color:#111>SGD</span><span style=color:#111>(</span><span style=color:#111>model</span><span style=color:#f92672>.</span><span style=color:#111>parameters</span><span style=color:#111>(),</span> <span style=color:#111>lr</span><span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>num_epochs</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span><span style=color:#111>inputs</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randn</span><span style=color:#111>(</span><span style=color:#ae81ff>64</span><span style=color:#111>,</span> <span style=color:#ae81ff>3</span><span style=color:#111>,</span> <span style=color:#ae81ff>32</span><span style=color:#111>,</span> <span style=color:#ae81ff>32</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>labels</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>randint</span><span style=color:#111>(</span><span style=color:#ae81ff>0</span><span style=color:#111>,</span> <span style=color:#ae81ff>10</span><span style=color:#111>,</span> <span style=color:#111>(</span><span style=color:#ae81ff>64</span><span style=color:#111>,))</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Train the model</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>for</span> <span style=color:#111>epoch</span> <span style=color:#f92672>in</span> <span style=color:#111>range</span><span style=color:#111>(</span><span style=color:#111>num_epochs</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Forward propagation</span>
</span></span><span style=display:flex><span>    <span style=color:#111>outputs</span> <span style=color:#f92672>=</span> <span style=color:#111>model</span><span style=color:#111>(</span><span style=color:#111>inputs</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>    <span style=color:#111>loss</span> <span style=color:#f92672>=</span> <span style=color:#111>criterion</span><span style=color:#111>(</span><span style=color:#111>outputs</span><span style=color:#111>,</span> <span style=color:#111>labels</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Backward propagation and optimization</span>
</span></span><span style=display:flex><span>    <span style=color:#111>optimizer</span><span style=color:#f92672>.</span><span style=color:#111>zero_grad</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>    <span style=color:#111>loss</span><span style=color:#f92672>.</span><span style=color:#111>backward</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>    <span style=color:#111>optimizer</span><span style=color:#f92672>.</span><span style=color:#111>step</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Print the training process</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>if</span> <span style=color:#111>(</span><span style=color:#111>epoch</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#111>)</span> <span style=color:#f92672>%</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span><span style=color:#111>:</span>
</span></span><span style=display:flex><span>        <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#d88200>&#39;Epoch [</span><span style=color:#d88200>{}</span><span style=color:#d88200>/</span><span style=color:#d88200>{}</span><span style=color:#d88200>], Loss: </span><span style=color:#d88200>{:.4f}</span><span style=color:#d88200>&#39;</span><span style=color:#f92672>.</span><span style=color:#111>format</span><span style=color:#111>(</span><span style=color:#111>epoch</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#111>,</span> <span style=color:#111>num_epochs</span><span style=color:#111>,</span> <span style=color:#111>loss</span><span style=color:#f92672>.</span><span style=color:#111>item</span><span style=color:#111>()))</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Predict</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>with</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>no_grad</span><span style=color:#111>():</span>
</span></span><span style=display:flex><span>    <span style=color:#111>outputs</span> <span style=color:#f92672>=</span> <span style=color:#111>model</span><span style=color:#111>(</span><span style=color:#111>inputs</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>    <span style=color:#111>_</span><span style=color:#111>,</span> <span style=color:#111>predicted</span> <span style=color:#f92672>=</span> <span style=color:#111>torch</span><span style=color:#f92672>.</span><span style=color:#111>max</span><span style=color:#111>(</span><span style=color:#111>outputs</span><span style=color:#f92672>.</span><span style=color:#111>data</span><span style=color:#111>,</span> <span style=color:#ae81ff>1</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>    <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>outputs</span><span style=color:#f92672>.</span><span style=color:#111>shape</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>will get:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Epoch <span style=color:#f92672>[</span>2/10<span style=color:#f92672>]</span>, Loss: 2.2880
</span></span><span style=display:flex><span>Epoch <span style=color:#f92672>[</span>4/10<span style=color:#f92672>]</span>, Loss: 2.2841
</span></span><span style=display:flex><span>Epoch <span style=color:#f92672>[</span>6/10<span style=color:#f92672>]</span>, Loss: 2.2805
</span></span><span style=display:flex><span>Epoch <span style=color:#f92672>[</span>8/10<span style=color:#f92672>]</span>, Loss: 2.2769
</span></span><span style=display:flex><span>Epoch <span style=color:#f92672>[</span>10/10<span style=color:#f92672>]</span>, Loss: 2.2734
</span></span><span style=display:flex><span>torch.Size<span style=color:#f92672>([</span>64, 10<span style=color:#f92672>])</span>
</span></span></code></pre></div><p>Start with torch&rsquo;s example <a href=https://github.com/pytorch/examples/blob/main/mnist>mnist</a> (or <a href=https://pytorch.org/tutorials/beginner/nn_tutorial.html><em>What is torch.nn really?</em></a>) is a great idea.</p><div class=post-date><span class="g time">June 14, 2023</span> &#8729;
<a href=https://ChenLi2049.github.io/tags/programming/>programming</a></div></section><div id=comments><script src=https://utteranc.es/client.js repo=ChenLi2049/ChenLi2049.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></main></body></html>