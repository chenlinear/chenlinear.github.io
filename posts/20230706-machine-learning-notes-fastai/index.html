<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Liste - https://chenlinear.github.io"><title>Machine Learning Notes: fastai | Chen Li</title><meta name=description content="Chen Li's personal blog"><meta property="og:title" content="Machine Learning Notes: fastai"><meta property="og:description" content="(Please refer to Wow It Fits! — Secondhand Machine Learning.)
Compared with tensorflow, mxnet, paddle or pure numpy (just for the fun of it), torch is probably the easiest Machine Learning package, and to get it even easier, let&rsquo;s take a look at fastai.
By the way, I subscribed GitHub Trending by RSS and the other day I got these two at the same time. Machine Learning in numpy is really cool, but the second one is like, why?"><meta property="og:type" content="article"><meta property="og:url" content="https://chenlinear.github.io/posts/20230706-machine-learning-notes-fastai/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-06T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-06T00:00:00+00:00"><meta itemprop=name content="Machine Learning Notes: fastai"><meta itemprop=description content="(Please refer to Wow It Fits! — Secondhand Machine Learning.)
Compared with tensorflow, mxnet, paddle or pure numpy (just for the fun of it), torch is probably the easiest Machine Learning package, and to get it even easier, let&rsquo;s take a look at fastai.
By the way, I subscribed GitHub Trending by RSS and the other day I got these two at the same time. Machine Learning in numpy is really cool, but the second one is like, why?"><meta itemprop=datePublished content="2023-07-06T00:00:00+00:00"><meta itemprop=dateModified content="2023-07-06T00:00:00+00:00"><meta itemprop=wordCount content="317"><meta itemprop=keywords content="programming,"><link rel=canonical href=https://chenlinear.github.io/posts/20230706-machine-learning-notes-fastai/><link rel=icon href=https://chenlinear.github.io/assets/favicon.ico><link rel=dns-prefetch href=https://www.google-analytics.com><link href=https://www.google-analytics.com rel=preconnect crossorigin><link rel=alternate type=application/atom+xml title="Chen Li" href=https://chenlinear.github.io/atom.xml><link rel=alternate type=application/json title="Chen Li" href=https://chenlinear.github.io/feed.json><link rel="shortcut icon" type=image/png href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="><style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-align:justify;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:rbg(169,169,169,1);color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5{font-size:20px;font-weight:600;text-align:center}strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a:hover,a.heading-link{text-decoration:none}a,a:visited{color:#008b8b}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:circle}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:90ch;margin:0 auto}header{line-height:1;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:135px;width:135px;position:relative;margin:0 0 0 15px;float:right;border-radius:25%}table{border-collapse:collapse}table th,table td{border:1px solid #bebebe;padding:0 5px}.toc{margin:0 auto;width:100%;padding:0;margin-bottom:10px;background-color:#f9f9f9}</style><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"posts","name":"Machine Learning Notes: fastai","headline":"Machine Learning Notes: fastai","alternativeHeadline":"","description":"(Please refer to Wow It Fits! — Secondhand Machine Learning.)\nCompared with tensorflow, mxnet, paddle or pure numpy (just for the fun of it), torch is probably the easiest Machine Learning package, and to get it even easier, let\u0026rsquo;s take a look at fastai.\nBy the way, I subscribed GitHub Trending by RSS and the other day I got these two at the same time. Machine Learning in numpy is really cool, but the second one is like, why?","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/chenlinear.github.io\/posts\/20230706-machine-learning-notes-fastai\/"},"author":{"@type":"Person","name":"Chen Li"},"creator":{"@type":"Person","name":"Chen Li"},"accountablePerson":{"@type":"Person","name":"Chen Li"},"copyrightHolder":"Chen Li","copyrightYear":"2023","dateCreated":"2023-07-06T00:00:00.00Z","datePublished":"2023-07-06T00:00:00.00Z","dateModified":"2023-07-06T00:00:00.00Z","publisher":{"@type":"Organization","name":"Chen Li","url":"https://chenlinear.github.io","logo":{"@type":"ImageObject","url":"https:\/\/chenlinear.github.io\/assets\/favicon.ico","width":"32","height":"32"}},"image":"https://chenlinear.github.io/assets/favicon.ico","url":"https:\/\/chenlinear.github.io\/posts\/20230706-machine-learning-notes-fastai\/","wordCount":"317","genre":["programming"],"keywords":["programming"]}</script></head><body><a class=skip-link href=#main>Skip to main</a><main id=main><div class=content><header><p style=padding:0;margin:0><a href=/><b>Chen Li</b>
<span class="text-stone-500 animate-blink"></span></a></p><ul style=padding:0;margin:0><li><a href=/cv/><span>CV</span></a><li><a href=/posts/><span>Posts</span></a><li><a href=/about/><span>About</span></a></li></ul></header><hr class=hr-list style=padding:0;margin:0><section><h2 class=post>Machine Learning Notes: fastai</h2><div class=toc><nav id=TableOfContents><ul><li><a href=#tabular-data>Tabular Data</a></li><li><a href=#transfer-learning-for-cv>Transfer Learning for CV</a></li><li><a href=#two-categories>Two Categories</a></li><li><a href=#learners><code>Learners</code></a></li></ul></nav></div><p>(Please refer to <a href=https://chenlinear.github.io/posts/20231011-wow-it-fits-secondhand-machine-learning/><em>Wow It Fits! — Secondhand Machine Learning</em></a>.)</p><p>Compared with <code>tensorflow</code>, <code>mxnet</code>, <code>paddle</code> or pure <code>numpy</code> (just for the fun of it), <code>torch</code> is probably the easiest Machine Learning package, and to get it even easier, let&rsquo;s take a look at <code>fastai</code>.</p><p>By the way, I subscribed GitHub Trending by RSS and the other day I got these two at the same time. Machine Learning in <code>numpy</code> is really cool, but the second one is like, why? &mldr; these two target markets do NOT overlap.</p><p><img src=20230706-machine-learning-notes-fastai-ml-np-py-excel.png alt=ml-in-np-python-in-excel loading=lazy decoding=async class=full-width></p><p>Back to the topic, here&rsquo;s my notes from <a href=https://docs.fast.ai/>fastai</a>, <a href=https://github.com/fastai/fastbook>fastbook (github.com)</a> and <a href=https://course.fast.ai/><em>Practical Deep Learning for Coders</em></a>. The main idea of <code>fastai</code> is to make Machine Learning accessible to every individual so that it can be applied to various subjects, and to do so:</p><ul><li>Use Google Colab, Kaggle, Paperspace, Hugging face.</li><li>Only requires one GPU (or at least try to).</li><li>fastai starts with higher architecture (see <a href=https://docs.fast.ai/quick_start.html>fastai - <em>Quick start</em></a>) and digs deeper so that it&rsquo;s more customizable. Nonetheless, some higher architectures are useful that you will see it in almost any project that uses <code>fastai</code>, for example, <code>DataLoaders</code> and <code>Learners</code>.</li></ul><h2 id=tabular-data>Tabular Data</h2><p>Random Forest is baseline, sometimes even the best method. See <a href=https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html>sklearn.ensemble.RandomForestClassifier — scikit-learn 1.3.0 documentation</a>.</p><h2 id=transfer-learning-for-cv>Transfer Learning for CV</h2><p>See <a href=https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning><em>The best vision models for fine-tuning</em> | Kaggle</a>.</p><h2 id=two-categories>Two Categories</h2><p>Sometimes predicting two categories at the same time has these two advantages:</p><ul><li>Parallel computing, which saves more time and computing sources.</li><li>The categories might help each other. For example, predicting the fish and the boat may produce better results than only predicting the fish.</li></ul><h2 id=learners><code>Learners</code></h2><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>fastai.vision.all</span> <span style=color:#f92672>import</span> <span style=color:#111>Learners</span>
</span></span><span style=display:flex><span><span style=color:#111>learn</span> <span style=color:#f92672>=</span> <span style=color:#111>Learners</span><span style=color:#111>(</span><span style=color:#f92672>...</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>See <a href=https://docs.fast.ai/examples/migrating_pytorch_verbose.html>fastai - <em>Pytorch to fastai details</em></a>. Here&rsquo;s some useful tricks:</p><ul><li><p>To find the best learning rate, see <a href=https://arxiv.org/abs/1506.01186>[1506.01186] <em>Cyclical Learning Rates for Training Neural Networks</em></a>:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>learn</span><span style=color:#f92672>.</span><span style=color:#111>lr_find</span><span style=color:#111>(</span><span style=color:#111>suggest_funcs</span><span style=color:#f92672>=</span><span style=color:#111>(</span><span style=color:#111>slide</span><span style=color:#111>,</span> <span style=color:#111>valley</span><span style=color:#111>))</span>
</span></span></code></pre></div></li><li><p>To test the model with a dummy:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#111>test_df</span> <span style=color:#f92672>=</span> <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span><span style=color:#111>test_dl</span> <span style=color:#f92672>=</span> <span style=color:#111>learn</span><span style=color:#f92672>.</span><span style=color:#111>dls</span><span style=color:#f92672>.</span><span style=color:#111>test_dl</span><span style=color:#111>(</span><span style=color:#111>test_df</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>preds</span><span style=color:#111>,</span> <span style=color:#111>_</span> <span style=color:#f92672>=</span> <span style=color:#111>learn</span><span style=color:#f92672>.</span><span style=color:#111>get_preds</span><span style=color:#111>(</span><span style=color:#111>dl</span><span style=color:#f92672>=</span><span style=color:#111>test_dl</span><span style=color:#111>)</span>
</span></span></code></pre></div></li></ul><div class=post-date><span class="g time">July 6, 2023</span> &#8729;
<a href=https://chenlinear.github.io/tags/programming/>programming</a></div></section><div id=comments><script src=https://utteranc.es/client.js repo=chenlinear/chenlinear.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></main></body></html>