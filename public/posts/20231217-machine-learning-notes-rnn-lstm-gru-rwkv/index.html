<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Liste - https://chenlinear.github.io">
    <title>Machine Learning Notes: RNN, LSTM, GRU, RWKV | Chen Li</title>
    <meta name="description" content="Chen Li&#39;s personal blog">
    <meta property="og:title" content="Machine Learning Notes: RNN, LSTM, GRU, RWKV" />
<meta property="og:description" content="&ldquo;Recurrent&rdquo; means that, hidden state $h_t$ is a function of the current input $x_t$ and the last hidden state $h_{t-1}$:$$h_t=f(x_t, h_{t-1}; \theta)$$where $\theta$ is all the trainable parameters. We iterate over each word (sub-word) in the entire sequence.
§1 RNN nn.RNNCell, nn.RNN
RNN (or vanilla RNN) is composed of 2 Linear layers and an activation function: $$h_t = \tanh(x_t W_{ih}^T &#43; b_{ih} &#43; h_{t-1}W_{hh}^T &#43; b_{hh})$$
Note that in the figure below each square represents the same parameters." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chenlinear.github.io/posts/20231217-machine-learning-notes-rnn-lstm-gru-rwkv/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-17T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-12-17T00:00:00+00:00" />

    <meta itemprop="name" content="Machine Learning Notes: RNN, LSTM, GRU, RWKV">
<meta itemprop="description" content="&ldquo;Recurrent&rdquo; means that, hidden state $h_t$ is a function of the current input $x_t$ and the last hidden state $h_{t-1}$:$$h_t=f(x_t, h_{t-1}; \theta)$$where $\theta$ is all the trainable parameters. We iterate over each word (sub-word) in the entire sequence.
§1 RNN nn.RNNCell, nn.RNN
RNN (or vanilla RNN) is composed of 2 Linear layers and an activation function: $$h_t = \tanh(x_t W_{ih}^T &#43; b_{ih} &#43; h_{t-1}W_{hh}^T &#43; b_{hh})$$
Note that in the figure below each square represents the same parameters."><meta itemprop="datePublished" content="2023-12-17T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-12-17T00:00:00+00:00" />
<meta itemprop="wordCount" content="3446">
<meta itemprop="keywords" content="programming," />
    
    <link rel="canonical" href="https://chenlinear.github.io/posts/20231217-machine-learning-notes-rnn-lstm-gru-rwkv/">
    <link rel="icon" href="https://chenlinear.github.io/assets/favicon.ico">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link href="https://www.google-analytics.com" rel="preconnect" crossorigin>
    <link rel="alternate" type="application/atom+xml" title="Chen Li" href="https://chenlinear.github.io/atom.xml" />
    <link rel="alternate" type="application/json" title="Chen Li" href="https://chenlinear.github.io/feed.json" />
    <link rel="shortcut icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII=">
    
    
    <style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-align:justify;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:rbg(169,169,169,1);color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5{font-size:20px;font-weight:600;text-align:center}strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a:hover,a.heading-link{text-decoration:none}a,a:visited{color:#008b8b}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:circle}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:90ch;margin:0 auto}header{line-height:1;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:135px;width:135px;position:relative;margin:0 0 0 15px;float:right;border-radius:25%} table{border-collapse:collapse}table th,table td{border:1px solid #bebebe;padding:0 5px}.toc{margin:0 auto;width:100%;padding:0;margin-bottom:10px;background-color:#f9f9f9}</style>
  
    
  
  
  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "BlogPosting",
      "articleSection": "posts",
      "name": "Machine Learning Notes: RNN, LSTM, GRU, RWKV",
      "headline": "Machine Learning Notes: RNN, LSTM, GRU, RWKV",
      "alternativeHeadline": "",
      "description": "\u0026ldquo;Recurrent\u0026rdquo; means that, hidden state $h_t$ is a function of the current input $x_t$ and the last hidden state $h_{t-1}$:$$h_t=f(x_t, h_{t-1}; \\theta)$$where $\\theta$ is all the trainable parameters. We iterate over each word (sub-word) in the entire sequence.\n§1 RNN nn.RNNCell, nn.RNN\nRNN (or vanilla RNN) is composed of 2 Linear layers and an activation function: $$h_t = \\tanh(x_t W_{ih}^T \u002b b_{ih} \u002b h_{t-1}W_{hh}^T \u002b b_{hh})$$\nNote that in the figure below each square represents the same parameters.",
      "inLanguage": "en-us",
      "isFamilyFriendly": "true",
      "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https:\/\/chenlinear.github.io\/posts\/20231217-machine-learning-notes-rnn-lstm-gru-rwkv\/"
      },
      "author" : {
          "@type": "Person",
          "name": "Chen Li"
      },
      "creator" : {
          "@type": "Person",
          "name": "Chen Li"
      },
      "accountablePerson" : {
          "@type": "Person",
          "name": "Chen Li"
      },
      "copyrightHolder" : "Chen Li",
      "copyrightYear" : "2023",
      "dateCreated": "2023-12-17T00:00:00.00Z",
      "datePublished": "2023-12-17T00:00:00.00Z",
      "dateModified": "2023-12-17T00:00:00.00Z",
      "publisher":{
          "@type":"Organization",
          "name": "Chen Li",
          "url": "https://chenlinear.github.io",
          "logo": {
              "@type": "ImageObject",
              "url": "https:\/\/chenlinear.github.io\/assets\/favicon.ico",
              "width":"32",
              "height":"32"
          }
      },
      "image": "https://chenlinear.github.io/assets/favicon.ico",
      "url" : "https:\/\/chenlinear.github.io\/posts\/20231217-machine-learning-notes-rnn-lstm-gru-rwkv\/",
      "wordCount" : "3446",
      "genre" : [ "programming" ],
      "keywords" : [ "programming" ]
  }
  </script>
  

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/katex.min.css">
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/katex.min.js"></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.6/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<script src="https://cdn.jsdelivr.net/npm/@xiee/utils/js/tabsets.min.js" defer></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@xiee/utils/css/tabsets.min.css">

  </head>

<body>
  <a class="skip-link" href="#main">Skip to main</a>
  <main id="main">
  <div class="content">
    <header>
<p style="padding: 0;margin: 0;">
  <a href="/">
    <b>Chen Li</b>
    <span class="text-stone-500 animate-blink"></span>
  </a>
</p>
<ul style="padding: 0;margin: 0;">
  
  
  <li class="">
    <a href="/cv/"><span>CV</span></a>
    
  <li class="">
    <a href="/posts/"><span>Posts</span></a>
    
  <li class="">
    <a href="/about/"><span>About</span></a>
    
  </li>
</ul>
</header>
<hr class="hr-list" style="padding: 0;margin: 0;">
    <section>
      <h2 class="post">Machine Learning Notes: RNN, LSTM, GRU, RWKV</h2>
      
      <div class="toc">
          <nav id="TableOfContents">
  <ul>
    <li><a href="#1-rnn">§1 RNN</a>
      <ul>
        <li><a href="#11-num_layers">§1.1 <code>num_layers</code></a></li>
        <li><a href="#12-bidirectional">§1.2 <code>bidirectional</code></a></li>
      </ul>
    </li>
    <li><a href="#2-lstm">§2 LSTM</a>
      <ul>
        <li><a href="#21-proj_size">§2.1 <code>proj_size</code></a></li>
      </ul>
    </li>
    <li><a href="#3-gru">§3 GRU</a></li>
    <li><a href="#4-rwkv-the-rnn-strikes-back">§4 RWKV: The RNN Strikes Back</a></li>
    <li><a href="#5-rnnlanguagemodel">§5 RNNLanguageModel</a>
      <ul>
        <li><a href="#41-dataset">§4.1 Dataset</a></li>
        <li><a href="#42-train-and-predict">§4.2 Train and Predict</a></li>
      </ul>
    </li>
  </ul>
</nav>
      </div>
      
      <p>&ldquo;Recurrent&rdquo; means that, hidden state $h_t$ is a function of the current input $x_t$ and the last hidden state $h_{t-1}$:$$h_t=f(x_t, h_{t-1}; \theta)$$where $\theta$ is all the trainable parameters. We iterate over each word (sub-word) in the entire sequence.</p>
<h2 id="1-rnn">§1 RNN</h2>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html"><code>nn.RNNCell</code></a>, <a href="https://pytorch.org/docs/stable/generated/torch.nn.RNN.html"><code>nn.RNN</code></a></p>
<p>RNN (or vanilla RNN) is composed of 2 Linear layers and an activation function: $$h_t = \tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})$$</p>
<p>Note that in the figure below each square represents the same parameters.</p>
<p><img
  src="20231217-machine-learning-notes-rnn-lstm-gru-rwkv-rnnscratch.svg"
  alt="RNNScratch"
  loading="lazy"
  decoding="async"
  class="full-width"
/>

</p>
<div class="tabset"></div>
<ul>
<li>
<p><code>RNNScratch</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#75af00">RNNScratch</span><span style="color:#111">(</span><span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Module</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#111">__init__</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">nonlinearity</span><span style="color:#f92672">=</span><span style="color:#d88200">&#39;tanh&#39;</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">super</span><span style="color:#111">()</span><span style="color:#f92672">.</span><span style="color:#111">__init__</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ih</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hh</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">if</span> <span style="color:#111">nonlinearity</span> <span style="color:#f92672">==</span> <span style="color:#d88200">&#39;tanh&#39;</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">act</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Tanh</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">elif</span> <span style="color:#111">nonlinearity</span> <span style="color:#f92672">==</span> <span style="color:#d88200">&#39;relu&#39;</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">act</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">ReLU</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">forward</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">Tensor</span><span style="color:#111">([])</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">h0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Iterate over the sequence of input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">x</span> <span style="color:#f92672">in</span> <span style="color:#111">input</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(&#39;x shape:&#39;, x.shape)# [batch_size, input_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">act</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ih</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hh</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(&#39;hn shape:&#39;, hn.shape)# [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span><span style="color:#111">),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(&#39;output shape:&#39;, output.shape)# [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># return, same as `torch.nn.RNN`</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span>
</span></span></code></pre></div></li>
<li>
<p>testing</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">rnn_scratch</span> <span style="color:#f92672">=</span> <span style="color:#111">RNNScratch</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">rnn_scratch</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#d88200">&#39;------&#39;</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#d88200">&#39;output shape:&#39;</span><span style="color:#111">,</span> <span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#d88200">&#39;hn shape:&#39;</span><span style="color:#111">,</span> <span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">all</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#111">[</span><span style="color:#ae81ff">4</span><span style="color:#111">:</span><span style="color:#ae81ff">5</span><span style="color:#111">]</span><span style="color:#f92672">==</span><span style="color:#111">hn</span><span style="color:#111">))</span><span style="color:#75715e"># y_{t-1} == h_t</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>x shape: torch.Size<span style="color:#f92672">([</span>16, 10<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>hn shape: torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>output shape: torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>x shape: torch.Size<span style="color:#f92672">([</span>16, 10<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>hn shape: torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>output shape: torch.Size<span style="color:#f92672">([</span>2, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>x shape: torch.Size<span style="color:#f92672">([</span>16, 10<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>hn shape: torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>output shape: torch.Size<span style="color:#f92672">([</span>3, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>x shape: torch.Size<span style="color:#f92672">([</span>16, 10<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>hn shape: torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>output shape: torch.Size<span style="color:#f92672">([</span>4, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>x shape: torch.Size<span style="color:#f92672">([</span>16, 10<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>hn shape: torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>output shape: torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>------
</span></span><span style="display:flex;"><span>output shape: torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>hn shape: torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">(</span>True<span style="color:#f92672">)</span>
</span></span></code></pre></div></li>
<li>
<p><code>nn.RNN</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">rnn</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">RNN</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">rnn</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">all</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#111">[</span><span style="color:#ae81ff">4</span><span style="color:#111">:</span><span style="color:#ae81ff">5</span><span style="color:#111">]</span><span style="color:#f92672">==</span><span style="color:#111">hn</span><span style="color:#111">))</span><span style="color:#75715e"># y_{t-1} == h_t</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">(</span>True<span style="color:#f92672">)</span>
</span></span></code></pre></div></li>
</ul>
<h3 id="11-num_layers">§1.1 <code>num_layers</code></h3>
<p><img
  src="20231217-machine-learning-notes-rnn-lstm-gru-rwkv-rnndeep.svg"
  alt="RNNDeep"
  loading="lazy"
  decoding="async"
  class="full-width"
/>

</p>
<div class="tabset"></div>
<ul>
<li>
<p><code>RNNDeep</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#75af00">RNNDeep</span><span style="color:#111">(</span><span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Module</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#111">__init__</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">nonlinearity</span><span style="color:#f92672">=</span><span style="color:#d88200">&#39;tanh&#39;</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">super</span><span style="color:#111">()</span><span style="color:#f92672">.</span><span style="color:#111">__init__</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">num_layers</span> <span style="color:#f92672">=</span> <span style="color:#111">num_layers</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnns</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">ModuleList</span><span style="color:#111">([</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">RNNScratch</span><span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>                <span style="color:#111">input_size</span> <span style="color:#00a8c8">if</span> <span style="color:#111">i</span><span style="color:#f92672">==</span><span style="color:#ae81ff">0</span> <span style="color:#00a8c8">else</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span>
</span></span><span style="display:flex;"><span>                <span style="color:#111">hidden_size</span><span style="color:#111">,</span>
</span></span><span style="display:flex;"><span>                <span style="color:#111">nonlinearity</span><span style="color:#111">,</span>
</span></span><span style="display:flex;"><span>                <span style="color:#111">bias</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">num_layers</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">forward</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">h0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Iterate over rnns</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">num_layers</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(hn[i:i+1].shape)# [1, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">]</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnns</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">](</span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># return, same as `torch.nn.RNN`</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span>
</span></span></code></pre></div></li>
<li>
<p>testing</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">rnn_deep</span> <span style="color:#f92672">=</span> <span style="color:#111">RNNDeep</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#f92672">=</span><span style="color:#ae81ff">3</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">3</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">rnn_deep</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>3, 16, 20<span style="color:#f92672">])</span>
</span></span></code></pre></div></li>
<li>
<p><code>nn.RNN</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">rnn</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">RNN</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#f92672">=</span><span style="color:#ae81ff">3</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">3</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">rnn</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>3, 16, 20<span style="color:#f92672">])</span>
</span></span></code></pre></div></li>
</ul>
<h3 id="12-bidirectional">§1.2 <code>bidirectional</code></h3>
<p><code>bidirecitonal=True</code> $\to D=2$</p>
<p><img
  src="20231217-machine-learning-notes-rnn-lstm-gru-rwkv-rnnbidirectional.svg"
  alt="RNNBidirectional"
  loading="lazy"
  decoding="async"
  class="full-width"
/>

</p>
<div class="tabset"></div>
<ul>
<li>
<p><code>RNNBidirectional</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#75af00">RNNBidirectional</span><span style="color:#111">(</span><span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Module</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#111">__init__</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">nonlinearity</span><span style="color:#f92672">=</span><span style="color:#d88200">&#39;tanh&#39;</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">super</span><span style="color:#111">()</span><span style="color:#f92672">.</span><span style="color:#111">__init__</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">num_layers</span> <span style="color:#f92672">=</span> <span style="color:#111">num_layers</span><span style="color:#75715e"># number of layers on one side</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnn_f</span> <span style="color:#f92672">=</span> <span style="color:#111">RNNDeep</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">nonlinearity</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnn_b</span> <span style="color:#f92672">=</span> <span style="color:#111">RNNDeep</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">nonlinearity</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">forward</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">seq_length</span> <span style="color:#f92672">=</span> <span style="color:#111">input</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">[</span><span style="color:#ae81ff">0</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># hn_f, hn_b = h0[:self.num_layers], h0[self.num_layers:]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn_f</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">[</span><span style="color:#111">h0</span><span style="color:#111">[</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">]</span> <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">num_layers</span><span style="color:#111">)],</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn_b</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">[</span><span style="color:#111">h0</span><span style="color:#111">[</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">:</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">2</span><span style="color:#111">]</span> <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">num_layers</span><span style="color:#111">)],</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output_f</span><span style="color:#111">,</span> <span style="color:#111">hn_f</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnn_f</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">hn_f</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output_b</span><span style="color:#111">,</span> <span style="color:#111">hn_b</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnn_b</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">flip</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">dims</span><span style="color:#f92672">=</span><span style="color:#111">[</span><span style="color:#ae81ff">0</span><span style="color:#111">]),</span> <span style="color:#111">hn_b</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output_b</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">flip</span><span style="color:#111">(</span><span style="color:#111">output_b</span><span style="color:#111">,</span> <span style="color:#111">dims</span><span style="color:#f92672">=</span><span style="color:#111">[</span><span style="color:#ae81ff">0</span><span style="color:#111">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">Tensor</span><span style="color:#111">([])</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># concat every y_i and z_i</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">seq_length</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">output_i</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">output_f</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">],</span> <span style="color:#111">output_b</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">]),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">2</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">output_i</span><span style="color:#111">),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">Tensor</span><span style="color:#111">([])</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># concat h_n, (h_n)&#39;, (h_n)&#39;&#39;, ...</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">num_layers</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">hn_i</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">hn_f</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">],</span> <span style="color:#111">hn_b</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">]),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">hn_i</span><span style="color:#111">),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span>
</span></span></code></pre></div></li>
<li>
<p>testing</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">rnn_bidirectional</span> <span style="color:#f92672">=</span> <span style="color:#111">RNNBidirectional</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#f92672">=</span><span style="color:#ae81ff">3</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">6</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">rnn_bidirectional</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">all</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#111">[</span><span style="color:#ae81ff">4</span><span style="color:#111">:</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#111">:,</span> <span style="color:#111">:</span><span style="color:#ae81ff">20</span><span style="color:#111">]</span><span style="color:#f92672">==</span><span style="color:#111">hn</span><span style="color:#111">[</span><span style="color:#ae81ff">4</span><span style="color:#111">:</span><span style="color:#ae81ff">5</span><span style="color:#111">]))</span><span style="color:#75715e"># ouput[seq_length-1:seq_length, :, :hidden_size] == hn[D * num_layers-2:D * num_layers-1]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">all</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#111">[</span><span style="color:#ae81ff">0</span><span style="color:#111">:</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#111">:,</span> <span style="color:#ae81ff">20</span><span style="color:#111">:]</span><span style="color:#f92672">==</span><span style="color:#111">hn</span><span style="color:#111">[</span><span style="color:#ae81ff">5</span><span style="color:#111">:</span><span style="color:#ae81ff">6</span><span style="color:#111">]))</span><span style="color:#75715e"># ouput[0:1, :, hidden_size:] == hn[D * num_layers-1:D * num_layers]</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 40<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>6, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">(</span>True<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">(</span>True<span style="color:#f92672">)</span>
</span></span></code></pre></div></li>
<li>
<p><code>nn.RNN</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">rnn</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">RNN</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">num_layers</span><span style="color:#f92672">=</span><span style="color:#ae81ff">3</span><span style="color:#111">,</span> <span style="color:#111">bidirectional</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">6</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">rnn</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">all</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#111">[</span><span style="color:#ae81ff">4</span><span style="color:#111">:</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#111">:,</span> <span style="color:#111">:</span><span style="color:#ae81ff">20</span><span style="color:#111">]</span><span style="color:#f92672">==</span><span style="color:#111">hn</span><span style="color:#111">[</span><span style="color:#ae81ff">4</span><span style="color:#111">:</span><span style="color:#ae81ff">5</span><span style="color:#111">]))</span><span style="color:#75715e"># ouput[seq_length-1:seq_length, :, :hidden_size] == hn[D * num_layers-2:D * num_layers-1]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">all</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#111">[</span><span style="color:#ae81ff">0</span><span style="color:#111">:</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#111">:,</span> <span style="color:#ae81ff">20</span><span style="color:#111">:]</span><span style="color:#f92672">==</span><span style="color:#111">hn</span><span style="color:#111">[</span><span style="color:#ae81ff">5</span><span style="color:#111">:</span><span style="color:#ae81ff">6</span><span style="color:#111">]))</span><span style="color:#75715e"># ouput[0:1, :, hidden_size:] == hn[D * num_layers-1:D * num_layers]</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 40<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>6, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">(</span>True<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>tensor<span style="color:#f92672">(</span>True<span style="color:#f92672">)</span>
</span></span></code></pre></div></li>
</ul>
<p>So we introduced two ways to stack up the layers: adding layers is like parallel connection in circuit; bidirectional is like series connection. In the following we will not explicitly write how to do these two ways, because (a) the code is pretty much the same; (b) <code>torch.nn.RNN</code>, <code>torch.nn.LSTM</code> and <code>torch.nn.GRU</code> do these implementations in C++ and CUDA, thus faster.</p>
<h2 id="2-lstm">§2 LSTM</h2>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html"><code>nn.LSTMCell</code></a>, <a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html"><code>nn.LSTM</code></a></p>
<p>LSTM introduces input gate $i_t$, forget gate $f_t$, cell gate $g_t$ and output gate $o_t$, which are functions of the current input $x_t$ and the last hidden state $h_{t-1}$: $$\begin{aligned} i_t &amp;= \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\ f_t &amp;= \sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\ g_t &amp;= \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\ o_t &amp;= \sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \end{aligned}$$then the current cell state $c_t$ and the current hidden state $h_t$ are:$$\begin{aligned} c_t &amp;= f_t \odot c_{t-1} + i_t \odot g_t \\ h_t &amp;= o_t \odot \tanh(c_t) \end{aligned}$$where $\sigma$ is the <a href="https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html">sigmoid function</a> $\sigma(x)=\frac{1}{1+e^{-x}} \in (0, 1)$ and $\odot$ is the <a href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)">Hadamard product</a>. I find <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">this post</a> and <a href="https://arxiv.org/abs/2410.01201">this summary paper</a> explaining the design motivation really well. By using sigmoid, the mechanism of these gates is that they are close to masks that marks what to forget and what to remember.</p>
<div class="tabset"></div>
<ul>
<li>
<p><code>LSTMScratch</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#75af00">LSTMScratch</span><span style="color:#111">(</span><span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Module</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#111">__init__</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">super</span><span style="color:#111">()</span><span style="color:#f92672">.</span><span style="color:#111">__init__</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ii</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hi</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_if</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hf</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ig</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hg</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_io</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ho</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Sigmoid</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Tanh</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">forward</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">Tensor</span><span style="color:#111">([])</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span> <span style="color:#f92672">=</span> <span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Iterate over the sequence of input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">x</span> <span style="color:#f92672">in</span> <span style="color:#111">input</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(&#39;x shape: &#39;, x.shape)# [batch_size, input_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">i_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ii</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hi</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">f_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_if</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hf</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">g_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ig</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hg</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">o_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_io</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ho</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">cn</span> <span style="color:#f92672">=</span> <span style="color:#111">f_t</span> <span style="color:#f92672">*</span> <span style="color:#111">cn</span> <span style="color:#f92672">+</span> <span style="color:#111">i_t</span> <span style="color:#f92672">*</span> <span style="color:#111">g_t</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">o_t</span> <span style="color:#f92672">*</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span><span style="color:#111">(</span><span style="color:#111">cn</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span><span style="color:#111">),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#111">)</span><span style="color:#75715e"># only hn is in the output</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># return, same as `torch.nn.LSTM`</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span><span style="color:#111">)</span>
</span></span></code></pre></div></li>
<li>
<p>testing</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">lstm_scratch</span> <span style="color:#f92672">=</span> <span style="color:#111">LSTMScratch</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">c0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">lstm_scratch</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">cn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as c0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span></code></pre></div></li>
<li>
<p><code>nn.LSTM</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">lstm</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">LSTM</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">c0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">lstm</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">cn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as c0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span></code></pre></div></li>
</ul>
<h3 id="21-proj_size">§2.1 <code>proj_size</code></h3>
<div class="tabset"></div>
<ul>
<li>
<p><code>LSTMProj</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#75af00">LSTMProj</span><span style="color:#111">(</span><span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Module</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#111">__init__</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">proj_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">super</span><span style="color:#111">()</span><span style="color:#f92672">.</span><span style="color:#111">__init__</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ii</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hi</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">proj_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span><span style="color:#75715e"># proj_size</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_if</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hf</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">proj_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span><span style="color:#75715e"># proj_size</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ig</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hg</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">proj_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span><span style="color:#75715e"># proj_size</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_io</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ho</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">proj_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span><span style="color:#75715e"># proj_size</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Sigmoid</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Tanh</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hr</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">proj_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">forward</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">Tensor</span><span style="color:#111">([])</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span> <span style="color:#f92672">=</span> <span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Iterate over the sequence of input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">x</span> <span style="color:#f92672">in</span> <span style="color:#111">input</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(&#39;x shape: &#39;, x.shape)# [batch_size, input_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">i_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ii</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hi</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">f_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_if</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hf</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">g_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ig</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hg</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">o_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_io</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ho</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">cn</span> <span style="color:#f92672">=</span> <span style="color:#111">f_t</span> <span style="color:#f92672">*</span> <span style="color:#111">cn</span> <span style="color:#f92672">+</span> <span style="color:#111">i_t</span> <span style="color:#f92672">*</span> <span style="color:#111">g_t</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">o_t</span> <span style="color:#f92672">*</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span><span style="color:#111">(</span><span style="color:#111">cn</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hr</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span><span style="color:#111">),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#111">)</span><span style="color:#75715e"># only hn is in the output</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># return, same as `torch.nn.LSTM`</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span><span style="color:#111">)</span>
</span></span></code></pre></div></li>
<li>
<p>testing</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">lstm_proj</span> <span style="color:#f92672">=</span> <span style="color:#111">LSTMProj</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">proj_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">15</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">15</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, proj_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">c0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">lstm_proj</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, proj_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">cn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as c0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 15<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 15<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span></code></pre></div></li>
<li>
<p><code>nn.LSTM</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">lstm</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">LSTM</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">proj_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">15</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">15</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, proj_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">c0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">,</span> <span style="color:#111">cn</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">lstm</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">h0</span><span style="color:#111">,</span> <span style="color:#111">c0</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, proj_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">cn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as c0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 15<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 15<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:879: UserWarning: LSTM with projections is not supported with oneDNN. Using default implementation. <span style="color:#f92672">(</span>Triggered internally at ../aten/src/ATen/native/RNN.cpp:1492.<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">result</span> <span style="color:#f92672">=</span> _VF.lstm<span style="color:#f92672">(</span>input, hx, self._flat_weights, self.bias, self.num_layers,
</span></span></code></pre></div><p>(the warning is about <a href="https://github.com/oneapi-src/oneDNN"><code>oneDNN</code></a>.)</p>
</li>
</ul>
<h2 id="3-gru">§3 GRU</h2>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html"><code>nn.GRUCell</code></a>, <a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html"><code>nn.GRU</code></a></p>
<p>GRU introduces reset gate $r_t$, update gate $z_t$ and new gate $n_t$, which are functions of the current input $x_t$ and the last hidden state $h_{t-1}$$$\begin{aligned} r_t &amp;= \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{t-1} + b_{hr}) \\ z_t &amp;= \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{t-1} + b_{hz}) \\ n_t &amp;= \tanh(W_{in} x_t + b_{in} + r_t \odot (W_{hn} h_{t-1}+ b_{hn})) \end{aligned}$$then the current hidden state $h_t$ is$$h_t = (1 - z_t) \odot n_t + z_t \odot h_{t-1}$$</p>
<div class="tabset"></div>
<ul>
<li>
<p><code>GRUScratch</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#75af00">GRUScratch</span><span style="color:#111">(</span><span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Module</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#111">__init__</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">super</span><span style="color:#111">()</span><span style="color:#f92672">.</span><span style="color:#111">__init__</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ir</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hr</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_iz</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hz</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_in</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hn</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">bias</span><span style="color:#f92672">=</span><span style="color:#111">bias</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Sigmoid</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Tanh</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">forward</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">Tensor</span><span style="color:#111">([])</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">h0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Iterate over the sequence of input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">x</span> <span style="color:#f92672">in</span> <span style="color:#111">input</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print(&#39;x shape: &#39;, x.shape)# [batch_size, input_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">r_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_ir</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hr</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">z_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">sigmoid</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_iz</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hz</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">n_t</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">tanh</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_in</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">+</span> <span style="color:#111">r_t</span> <span style="color:#f92672">*</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">w_hn</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">(</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> <span style="color:#111">z_t</span><span style="color:#111">)</span> <span style="color:#f92672">*</span> <span style="color:#111">n_t</span> <span style="color:#f92672">+</span> <span style="color:#111">z_t</span> <span style="color:#f92672">*</span> <span style="color:#111">hn</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">output</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span><span style="color:#111">),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># return, same as `torch.nn.LSTM`</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span>
</span></span></code></pre></div></li>
<li>
<p>testing</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">gru_scratch</span> <span style="color:#f92672">=</span> <span style="color:#111">GRUScratch</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">gru_scratch</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span></code></pre></div></li>
<li>
<p><code>nn.GRU</code></p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">gru</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">GRU</span><span style="color:#111">(</span><span style="color:#111">input_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randn</span><span style="color:#111">(</span><span style="color:#ae81ff">5</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">10</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, input_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">16</span><span style="color:#111">,</span> <span style="color:#ae81ff">20</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">output</span><span style="color:#111">,</span> <span style="color:#111">hn</span> <span style="color:#f92672">=</span> <span style="color:#111">gru</span><span style="color:#111">(</span><span style="color:#111">input</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">output</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">hn</span><span style="color:#f92672">.</span><span style="color:#111">shape</span><span style="color:#111">)</span><span style="color:#75715e"># same as h0</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>5, 16, 20<span style="color:#f92672">])</span>
</span></span><span style="display:flex;"><span>torch.Size<span style="color:#f92672">([</span>1, 16, 20<span style="color:#f92672">])</span>
</span></span></code></pre></div></li>
</ul>
<h2 id="4-rwkv-the-rnn-strikes-back">§4 RWKV: The RNN Strikes Back</h2>
<p>| <a href="https://arxiv.org/abs/2305.13048">[2305.13048] <em>RWKV: Reinventing RNNs for the Transformer Era</em></a> | <a href="https://github.com/BlinkDL/RWKV-LM">RWKV-LM (GitHub)</a> | <a href="https://github.com/BlinkDL/nanoRWKV">nanoRWKV (GitHub)</a> | <a href="https://github.com/harrisonvanderbyl/rwkv-cpp-accelerated">rwkv-cpp-accelerated (GitHub)</a> |</p>
<p>Receptance Weighted Key Value (RWKV) combines the efficient parallelizable training of transformers with the efficient inference of RNNs. Generally speaking it&rsquo;s composed of several layers of Time Mix module and Channel Mix module. It can be considered as a convolutional network across an entire one-dimensional sequence (because $r_t$, $k_t$, $v_t$ does not contain non-linearity thus are weighted sum), which is the same thing we will see in SSM.</p>
<ul>
<li>
<p>The Time Mix module is linear projections ($W$) of linear combinations ($\mu$ and $(1-\mu)$) of the current input $x_t$ and the last input $x_{t-1}$, $wkv_t$ is weighted sum over the entire past sequence:$$\begin{aligned} r_t &amp;= W_r (\mu_r \odot x_t + (1-\mu_r) \odot x_{t-1}) \\ k_t &amp;= W_k (\mu_k \odot x_t + (1-\mu_k) \odot x_{t-1}) \\ v_t &amp;= W_v (\mu_v \odot x_t + (1-\mu_v) \odot x_{t-1}) \\ wkv_t &amp;= \frac{ \sum_{i=1}^{t-1} e^{-(t-1-i)w+k_i} \odot v_i + e^{u+k_t} \odot v_t }{\sum_{i=1}^{t-1} e^{-(t-1-i)w+k_i} + e^{u+k_t}} \\ o_t &amp;= W_o (\sigma(r_t) \odot wkv_t) \end{aligned}$$</p>
</li>
<li>
<p>The Channel Mix module is $$\begin{aligned} r_t &amp;= W_r (\mu_r \odot x_t + (1 - \mu_r) \odot x_{t-1} ) \\ k_t &amp;= W_k (\mu_k \odot x_t + (1 - \mu_k) \odot x_{t-1} ) \\ o_t &amp;= \sigma(r_t) \odot (W_v \max({k_t}, 0)^2) \end{aligned}$$</p>
</li>
</ul>
<p>The usage of $x_t$ and $x_{t-1}$ is the &ldquo;Token shift&rdquo; in Fig.3 of the paper:</p>
<p><img
  src="https://pbs.twimg.com/media/FwyDRLvaQAEBYok?format=png"
  alt="fig3_of_2305.13048"
  loading="lazy"
  decoding="async"
  class="full-width"
/>

</p>
<p><a href="https://twitter.com/BlinkDL_AI/status/1735258602473197721">RWKV-v6</a> looks scary&hellip;</p>
<p><img
  src="https://pbs.twimg.com/media/GBTgK7TbYAAeeCN?format=jpg"
  alt="RWKV-v6"
  loading="lazy"
  decoding="async"
  class="full-width"
/>

</p>
<h2 id="5-rnnlanguagemodel">§5 RNNLanguageModel</h2>
<p>The detailed code to train a language model is largely from <a href="https://github.com/karpathy/nanoGPT">nanoGPT</a>. Please refer to <a href="https://github.com/pytorch-labs/gpt-fast/">gpt-fast</a> for training on a larger (like, way larger) dataset.</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#75af00">RNNLanguageModel</span><span style="color:#111">(</span><span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Module</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#111">__init__</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">vocab_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">emb_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">10</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">20</span><span style="color:#111">,</span> <span style="color:#111">window_size</span><span style="color:#f92672">=</span><span style="color:#ae81ff">8</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">super</span><span style="color:#111">()</span><span style="color:#f92672">.</span><span style="color:#111">__init__</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">hidden_size</span> <span style="color:#f92672">=</span> <span style="color:#111">hidden_size</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">embedding</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Embedding</span><span style="color:#111">(</span><span style="color:#111">vocab_size</span><span style="color:#111">,</span> <span style="color:#111">emb_size</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">pos_embedding</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Embedding</span><span style="color:#111">(</span><span style="color:#111">window_size</span><span style="color:#111">,</span> <span style="color:#111">emb_size</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnn</span> <span style="color:#f92672">=</span> <span style="color:#111">RNNScratch</span><span style="color:#111">(</span><span style="color:#111">emb_size</span><span style="color:#111">,</span> <span style="color:#111">hidden_size</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">layer_norm</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">LayerNorm</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">proj</span> <span style="color:#f92672">=</span> <span style="color:#111">nn</span><span style="color:#f92672">.</span><span style="color:#111">Linear</span><span style="color:#111">(</span><span style="color:#111">hidden_size</span><span style="color:#111">,</span> <span style="color:#111">vocab_size</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">forward</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">index</span><span style="color:#111">,</span> <span style="color:#111">targets</span><span style="color:#f92672">=</span><span style="color:#00a8c8">None</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># index, targets shape: [batch_size, seq_length]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">batch_size</span><span style="color:#111">,</span> <span style="color:#111">seq_length</span> <span style="color:#f92672">=</span> <span style="color:#111">index</span><span style="color:#f92672">.</span><span style="color:#111">shape</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># embedding</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">embedding</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">embedding</span><span style="color:#111">(</span><span style="color:#111">index</span><span style="color:#111">)</span><span style="color:#75715e"># [batch_size, seq_length, emb_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">pos_embedding</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">pos_embedding</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">arange</span><span style="color:#111">(</span><span style="color:#111">seq_length</span><span style="color:#111">))</span><span style="color:#75715e"># [seq_length, emb_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">embedding</span> <span style="color:#f92672">+</span> <span style="color:#111">pos_embedding</span><span style="color:#75715e"># [batch_size, seq_length, emb_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># RNN</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">x</span><span style="color:#f92672">.</span><span style="color:#111">permute</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">0</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">)</span><span style="color:#75715e"># [seq_length, batch_size, emb_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">h0</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#111">batch_size</span><span style="color:#111">,</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">hidden_size</span><span style="color:#111">)</span><span style="color:#75715e"># [D * num_layers, batch_size, hidden_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">_</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">rnn</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">h0</span><span style="color:#111">)</span> <span style="color:#75715e"># x shape: [seq_length, batch_size, D * hidden_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">x</span><span style="color:#f92672">.</span><span style="color:#111">permute</span><span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">0</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">)</span><span style="color:#75715e"># [batch_size, seq_length, D * hidden_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># project out</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">layer_norm</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span><span style="color:#75715e"># [batch_size, seq_length, D * hidden_size]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">logits</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#f92672">.</span><span style="color:#111">proj</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">)</span><span style="color:#75715e"># [batch_size, seq_length, vocab_size]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">if</span> <span style="color:#111">targets</span> <span style="color:#f92672">is</span> <span style="color:#00a8c8">None</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">loss</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">None</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">else</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">batch_size</span><span style="color:#111">,</span> <span style="color:#111">seq_length</span><span style="color:#111">,</span> <span style="color:#111">vocab_size</span> <span style="color:#f92672">=</span> <span style="color:#111">logits</span><span style="color:#f92672">.</span><span style="color:#111">shape</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">logits</span> <span style="color:#f92672">=</span> <span style="color:#111">logits</span><span style="color:#f92672">.</span><span style="color:#111">view</span><span style="color:#111">(</span><span style="color:#111">batch_size</span><span style="color:#f92672">*</span><span style="color:#111">seq_length</span><span style="color:#111">,</span> <span style="color:#111">vocab_size</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">targets</span> <span style="color:#f92672">=</span> <span style="color:#111">targets</span><span style="color:#f92672">.</span><span style="color:#111">view</span><span style="color:#111">(</span><span style="color:#111">batch_size</span><span style="color:#f92672">*</span><span style="color:#111">seq_length</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">loss</span> <span style="color:#f92672">=</span> <span style="color:#111">F</span><span style="color:#f92672">.</span><span style="color:#111">cross_entropy</span><span style="color:#111">(</span><span style="color:#111">logits</span><span style="color:#111">,</span> <span style="color:#111">targets</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">logits</span><span style="color:#111">,</span> <span style="color:#111">loss</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75af00">@torch.no_grad</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">def</span> <span style="color:#75af00">generate</span><span style="color:#111">(</span><span style="color:#111">self</span><span style="color:#111">,</span> <span style="color:#111">index</span><span style="color:#111">,</span> <span style="color:#111">max_new_tokens</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># index shape [batch_size, seq_length]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">_</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">max_new_tokens</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># crop index to the last window_size tokens</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">index_cond</span> <span style="color:#f92672">=</span> <span style="color:#111">index</span><span style="color:#111">[:,</span> <span style="color:#f92672">-</span><span style="color:#111">window_size</span><span style="color:#111">:]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># get the predictions</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">logits</span><span style="color:#111">,</span> <span style="color:#111">loss</span> <span style="color:#f92672">=</span> <span style="color:#111">self</span><span style="color:#111">(</span><span style="color:#111">index_cond</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># focus only on the last time step</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">logits</span> <span style="color:#f92672">=</span> <span style="color:#111">logits</span><span style="color:#111">[:,</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#111">:]</span> <span style="color:#75715e"># [batch_size, vocab_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># apply softmax to get probabilities</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">probs</span> <span style="color:#f92672">=</span> <span style="color:#111">F</span><span style="color:#f92672">.</span><span style="color:#111">softmax</span><span style="color:#111">(</span><span style="color:#111">logits</span><span style="color:#111">,</span> <span style="color:#111">dim</span><span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span><span style="color:#111">)</span> <span style="color:#75715e"># [batch_size, vocab_size]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># sample from the distribution</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">index_next</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">multinomial</span><span style="color:#111">(</span><span style="color:#111">probs</span><span style="color:#111">,</span> <span style="color:#111">num_samples</span><span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#111">)</span> <span style="color:#75715e"># [batch_size, 1]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># append sampled index to the running sequence</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">index</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">cat</span><span style="color:#111">((</span><span style="color:#111">index</span><span style="color:#111">,</span> <span style="color:#111">index_next</span><span style="color:#111">),</span> <span style="color:#111">dim</span><span style="color:#f92672">=</span><span style="color:#ae81ff">1</span><span style="color:#111">)</span> <span style="color:#75715e"># [batch_size, seq_length+1]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">return</span> <span style="color:#111">index</span>
</span></span></code></pre></div><h3 id="41-dataset">§4.1 Dataset</h3>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">text</span> <span style="color:#f92672">=</span> <span style="color:#d88200">&#39;&#39;&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">All work and no play makes Jack a doll boy. 
</span></span></span><span style="display:flex;"><span><span style="color:#d88200">&#39;&#39;&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># https://docs.python.org/3/library/re.html#raw-string-notation</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># text = &#39;All work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \n&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># text = r&#39;All work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \nAll work and no play makes Jack a doll boy. \n&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">text</span><span style="color:#111">[:</span><span style="color:#ae81ff">100</span><span style="color:#111">])</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>All work and no play makes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work and no play makes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work a
</span></span></code></pre></div><p>Here&rsquo;s a character-level tokenizer, please refer to <a href="https://github.com/openai/tiktoken"><code>tiktoken</code></a> or <a href="https://github.com/karpathy/minbpe/"><code>minbpe</code></a> (BPE is combining words to get pharses) for a sub-word-level tokenizer.</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">characters</span> <span style="color:#f92672">=</span> <span style="color:#111">sorted</span><span style="color:#111">(</span><span style="color:#111">list</span><span style="color:#111">(</span><span style="color:#111">set</span><span style="color:#111">(</span><span style="color:#111">text</span><span style="color:#111">)))</span>
</span></span><span style="display:flex;"><span><span style="color:#111">vocab_size</span> <span style="color:#f92672">=</span> <span style="color:#111">len</span><span style="color:#111">(</span><span style="color:#111">characters</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#d88200">&#39;&#39;</span><span style="color:#f92672">.</span><span style="color:#111">join</span><span style="color:#111">(</span><span style="color:#111">characters</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">vocab_size</span><span style="color:#111">)</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>.AJabcdeklmnoprswy
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">20</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">string_to_int</span> <span style="color:#f92672">=</span> <span style="color:#111">{</span> <span style="color:#111">character</span><span style="color:#111">:</span><span style="color:#111">integer</span> <span style="color:#00a8c8">for</span> <span style="color:#111">integer</span><span style="color:#111">,</span><span style="color:#111">character</span> <span style="color:#f92672">in</span> <span style="color:#111">enumerate</span><span style="color:#111">(</span><span style="color:#111">characters</span><span style="color:#111">)</span> <span style="color:#111">}</span>
</span></span><span style="display:flex;"><span><span style="color:#111">int_to_string</span> <span style="color:#f92672">=</span> <span style="color:#111">{</span> <span style="color:#111">interger</span><span style="color:#111">:</span><span style="color:#111">character</span> <span style="color:#00a8c8">for</span> <span style="color:#111">interger</span><span style="color:#111">,</span><span style="color:#111">character</span> <span style="color:#f92672">in</span> <span style="color:#111">enumerate</span><span style="color:#111">(</span><span style="color:#111">characters</span><span style="color:#111">)</span> <span style="color:#111">}</span>
</span></span><span style="display:flex;"><span><span style="color:#111">encode</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">lambda</span> <span style="color:#111">strings</span><span style="color:#111">:</span> <span style="color:#111">[</span><span style="color:#111">string_to_int</span><span style="color:#111">[</span><span style="color:#111">string</span><span style="color:#111">]</span> <span style="color:#00a8c8">for</span> <span style="color:#111">string</span> <span style="color:#f92672">in</span> <span style="color:#111">strings</span><span style="color:#111">]</span> <span style="color:#75715e"># string -&gt; a list of integers</span>
</span></span><span style="display:flex;"><span><span style="color:#111">decode</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">lambda</span> <span style="color:#111">ints</span><span style="color:#111">:</span> <span style="color:#d88200">&#39;&#39;</span><span style="color:#f92672">.</span><span style="color:#111">join</span><span style="color:#111">([</span><span style="color:#111">int_to_string</span><span style="color:#111">[</span><span style="color:#111">integer</span><span style="color:#111">]</span> <span style="color:#00a8c8">for</span> <span style="color:#111">integer</span> <span style="color:#f92672">in</span> <span style="color:#111">ints</span><span style="color:#111">])</span> <span style="color:#75715e"># a list of integers -&gt; string</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">encode</span><span style="color:#111">(</span><span style="color:#d88200">&#39;cJ&#39;</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">decode</span><span style="color:#111">([</span><span style="color:#ae81ff">7</span><span style="color:#111">,</span> <span style="color:#ae81ff">4</span><span style="color:#111">]))</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">[</span>7, 4<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>cJ
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">data</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">Tensor</span><span style="color:#111">(</span><span style="color:#111">encode</span><span style="color:#111">(</span><span style="color:#111">text</span><span style="color:#111">))</span><span style="color:#f92672">.</span><span style="color:#111">to</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">long</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">n</span> <span style="color:#f92672">=</span> <span style="color:#111">int</span><span style="color:#111">(</span><span style="color:#ae81ff">0.9</span><span style="color:#f92672">*</span><span style="color:#111">len</span><span style="color:#111">(</span><span style="color:#111">data</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span><span style="color:#111">train_data</span> <span style="color:#f92672">=</span> <span style="color:#111">data</span><span style="color:#111">[:</span><span style="color:#111">n</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#111">val_data</span> <span style="color:#f92672">=</span> <span style="color:#111">data</span><span style="color:#111">[</span><span style="color:#111">n</span><span style="color:#111">:]</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">batch_size</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span><span style="color:#111">window_size</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">def</span> <span style="color:#75af00">get_batch</span><span style="color:#111">(</span><span style="color:#111">split</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># generate a small batch of data of inputs x and targets y</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">if</span> <span style="color:#111">split</span> <span style="color:#f92672">==</span> <span style="color:#d88200">&#39;train&#39;</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">data</span> <span style="color:#f92672">=</span> <span style="color:#111">train_data</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">else</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">data</span> <span style="color:#f92672">=</span> <span style="color:#111">val_data</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">ix</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">randint</span><span style="color:#111">(</span><span style="color:#111">len</span><span style="color:#111">(</span><span style="color:#111">data</span><span style="color:#111">)</span> <span style="color:#f92672">-</span> <span style="color:#111">window_size</span><span style="color:#111">,</span> <span style="color:#111">(</span><span style="color:#111">batch_size</span><span style="color:#111">,))</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">stack</span><span style="color:#111">([</span><span style="color:#111">data</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#111">window_size</span><span style="color:#111">]</span> <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">ix</span><span style="color:#111">])</span><span style="color:#75715e"># [batch_size, window_size]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">y</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">stack</span><span style="color:#111">([</span><span style="color:#111">data</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">:</span><span style="color:#111">i</span><span style="color:#f92672">+</span><span style="color:#111">window_size</span><span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#111">]</span> <span style="color:#00a8c8">for</span> <span style="color:#111">i</span> <span style="color:#f92672">in</span> <span style="color:#111">ix</span><span style="color:#111">])</span><span style="color:#75715e"># [batch_size, window_size]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">return</span> <span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">y</span>
</span></span></code></pre></div><h3 id="42-train-and-predict">§4.2 Train and Predict</h3>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">eval_iters</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">200</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">@torch.no_grad</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">def</span> <span style="color:#75af00">estimate_loss</span><span style="color:#111">():</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">out</span> <span style="color:#f92672">=</span> <span style="color:#111">{}</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">model</span><span style="color:#f92672">.</span><span style="color:#111">eval</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">for</span> <span style="color:#111">split</span> <span style="color:#f92672">in</span> <span style="color:#111">[</span><span style="color:#d88200">&#39;train&#39;</span><span style="color:#111">,</span> <span style="color:#d88200">&#39;val&#39;</span><span style="color:#111">]:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">losses</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">(</span><span style="color:#111">eval_iters</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">for</span> <span style="color:#111">k</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">eval_iters</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">X</span><span style="color:#111">,</span> <span style="color:#111">Y</span> <span style="color:#f92672">=</span> <span style="color:#111">get_batch</span><span style="color:#111">(</span><span style="color:#111">split</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">logits</span><span style="color:#111">,</span> <span style="color:#111">loss</span> <span style="color:#f92672">=</span> <span style="color:#111">model</span><span style="color:#111">(</span><span style="color:#111">X</span><span style="color:#111">,</span> <span style="color:#111">Y</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>            <span style="color:#111">losses</span><span style="color:#111">[</span><span style="color:#111">k</span><span style="color:#111">]</span> <span style="color:#f92672">=</span> <span style="color:#111">loss</span><span style="color:#f92672">.</span><span style="color:#111">item</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">out</span><span style="color:#111">[</span><span style="color:#111">split</span><span style="color:#111">]</span> <span style="color:#f92672">=</span> <span style="color:#111">losses</span><span style="color:#f92672">.</span><span style="color:#111">mean</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">model</span><span style="color:#f92672">.</span><span style="color:#111">train</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">return</span> <span style="color:#111">out</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">manual_seed</span><span style="color:#111">(</span><span style="color:#ae81ff">2001</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#111">model</span> <span style="color:#f92672">=</span> <span style="color:#111">RNNLanguageModel</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span><span style="color:#111">optimizer</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">optim</span><span style="color:#f92672">.</span><span style="color:#111">AdamW</span><span style="color:#111">(</span><span style="color:#111">model</span><span style="color:#f92672">.</span><span style="color:#111">parameters</span><span style="color:#111">(),</span> <span style="color:#111">lr</span><span style="color:#f92672">=</span><span style="color:#ae81ff">1e-3</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># train</span>
</span></span><span style="display:flex;"><span><span style="color:#111">max_iters</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">2000</span>
</span></span><span style="display:flex;"><span><span style="color:#111">eval_interval</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">for</span> <span style="color:#111">iter</span> <span style="color:#f92672">in</span> <span style="color:#111">range</span><span style="color:#111">(</span><span style="color:#111">max_iters</span><span style="color:#111">):</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># every once in a while evaluate the loss on train and val sets</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">if</span> <span style="color:#111">iter</span> <span style="color:#f92672">%</span> <span style="color:#111">eval_interval</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">or</span> <span style="color:#111">iter</span> <span style="color:#f92672">==</span> <span style="color:#111">max_iters</span> <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span><span style="color:#111">:</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">losses</span> <span style="color:#f92672">=</span> <span style="color:#111">estimate_loss</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#d88200">f</span><span style="color:#d88200">&#34;step </span><span style="color:#d88200">{</span><span style="color:#111">iter</span><span style="color:#d88200">}</span><span style="color:#d88200">: train loss </span><span style="color:#d88200">{</span><span style="color:#111">losses</span><span style="color:#111">[</span><span style="color:#d88200">&#39;train&#39;</span><span style="color:#111">]</span><span style="color:#d88200">:</span><span style="color:#d88200">.4f</span><span style="color:#d88200">}</span><span style="color:#d88200">, val loss </span><span style="color:#d88200">{</span><span style="color:#111">losses</span><span style="color:#111">[</span><span style="color:#d88200">&#39;val&#39;</span><span style="color:#111">]</span><span style="color:#d88200">:</span><span style="color:#d88200">.4f</span><span style="color:#d88200">}</span><span style="color:#d88200">&#34;</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># sample a batch of data</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">xb</span><span style="color:#111">,</span> <span style="color:#111">yb</span> <span style="color:#f92672">=</span> <span style="color:#111">get_batch</span><span style="color:#111">(</span><span style="color:#d88200">&#39;train&#39;</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># evaluate the loss</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">logits</span><span style="color:#111">,</span> <span style="color:#111">loss</span> <span style="color:#f92672">=</span> <span style="color:#111">model</span><span style="color:#111">(</span><span style="color:#111">xb</span><span style="color:#111">,</span> <span style="color:#111">yb</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">optimizer</span><span style="color:#f92672">.</span><span style="color:#111">zero_grad</span><span style="color:#111">(</span><span style="color:#111">set_to_none</span><span style="color:#f92672">=</span><span style="color:#00a8c8">True</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">loss</span><span style="color:#f92672">.</span><span style="color:#111">backward</span><span style="color:#111">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">optimizer</span><span style="color:#f92672">.</span><span style="color:#111">step</span><span style="color:#111">()</span>
</span></span></code></pre></div><p>will get:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>step 0: train loss 3.0177, val loss 3.0082
</span></span><span style="display:flex;"><span>step 100: train loss 2.2342, val loss 2.1759
</span></span><span style="display:flex;"><span>step 200: train loss 1.5963, val loss 1.5902
</span></span><span style="display:flex;"><span>step 300: train loss 1.1176, val loss 1.1208
</span></span><span style="display:flex;"><span>step 400: train loss 0.7405, val loss 0.7353
</span></span><span style="display:flex;"><span>step 500: train loss 0.5035, val loss 0.4992
</span></span><span style="display:flex;"><span>step 600: train loss 0.3738, val loss 0.3645
</span></span><span style="display:flex;"><span>step 700: train loss 0.3333, val loss 0.3219
</span></span><span style="display:flex;"><span>step 800: train loss 0.2738, val loss 0.2673
</span></span><span style="display:flex;"><span>step 900: train loss 0.2465, val loss 0.2517
</span></span><span style="display:flex;"><span>step 1000: train loss 0.2248, val loss 0.2286
</span></span><span style="display:flex;"><span>step 1100: train loss 0.2163, val loss 0.2102
</span></span><span style="display:flex;"><span>step 1200: train loss 0.1975, val loss 0.2043
</span></span><span style="display:flex;"><span>step 1300: train loss 0.1981, val loss 0.1930
</span></span><span style="display:flex;"><span>step 1400: train loss 0.1873, val loss 0.1965
</span></span><span style="display:flex;"><span>step 1500: train loss 0.1792, val loss 0.1813
</span></span><span style="display:flex;"><span>step 1600: train loss 0.1752, val loss 0.1775
</span></span><span style="display:flex;"><span>step 1700: train loss 0.1713, val loss 0.1809
</span></span><span style="display:flex;"><span>step 1800: train loss 0.1673, val loss 0.1762
</span></span><span style="display:flex;"><span>step 1900: train loss 0.1762, val loss 0.1739
</span></span><span style="display:flex;"><span>step 1999: train loss 0.1697, val loss 0.1724
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># generate from the trained model</span>
</span></span><span style="display:flex;"><span><span style="color:#111">context</span> <span style="color:#f92672">=</span> <span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">zeros</span><span style="color:#111">((</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">1</span><span style="color:#111">))</span><span style="color:#f92672">.</span><span style="color:#111">to</span><span style="color:#111">(</span><span style="color:#111">torch</span><span style="color:#f92672">.</span><span style="color:#111">long</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># context = torch.unsqueeze(torch.Tensor(encode(&#39;cJ&#39;)).to(torch.long), dim=0)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">print</span><span style="color:#111">(</span><span style="color:#111">decode</span><span style="color:#111">(</span><span style="color:#111">model</span><span style="color:#f92672">.</span><span style="color:#111">generate</span><span style="color:#111">(</span><span style="color:#111">context</span><span style="color:#111">,</span> <span style="color:#111">max_new_tokens</span><span style="color:#f92672">=</span><span style="color:#ae81ff">500</span><span style="color:#111">)[</span><span style="color:#ae81ff">0</span><span style="color:#111">]</span><span style="color:#f92672">.</span><span style="color:#111">tolist</span><span style="color:#111">()))</span>
</span></span></code></pre></div><p>will get Jack Torrance played by Jack Nicholson:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>All boy. 
</span></span><span style="display:flex;"><span>All work and no plakes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work and no play. 
</span></span><span style="display:flex;"><span>All work and no play makesl play makes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work and no play makes Jack a doll boy.. 
</span></span><span style="display:flex;"><span>All work and no play makes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work and no play makes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work and no play makes Jack a Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work and no play makes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work amakes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work ank a doll boy. 
</span></span><span style="display:flex;"><span>Alak a d no playes Jack a doll boy. 
</span></span><span style="display:flex;"><span>All work and no play makes Jack a doll
</span></span></code></pre></div><p>By the way, I guess the reasons Transformers outperform RNNs are:</p>
<ul>
<li>Transformers don&rsquo;t use <code>for</code> loops thus are more parallel-processing-friendly. (There is this new architecture with Transformers that the same single Transformer layer is repeated several times, which is like using Transformer layer as RNN layer.)</li>
<li>Transformers can look into the entire sequence equally while RNNs focus more on the current input of the entire sequence.</li>
</ul>
<p>On the other hand, the advantages of RNNs are:</p>
<ul>
<li>The scaling of memory usage is linear (Transformers are quadratically, please refer to Tab.1 of <a href="https://arxiv.org/abs/2305.13048">[2305.13048] <em>RWKV: Reinventing RNNs for the Transformer Era</em></a>).</li>
<li>The memory usage is constant, because <code>hn</code> is passed down.</li>
</ul>

      
      <div class="post-date">
        <span class="g time">December 17, 2023 </span> &#8729;
         
         <a href="https://chenlinear.github.io/tags/programming/">programming</a>
      </div>
      
    </section>
    
    <div id="comments">
      <script src="https://utteranc.es/client.js"
    repo=chenlinear/chenlinear.github.io
    issue-term="pathname"
    theme=github-light
    crossorigin="anonymous"
    async>
</script>

    </div>
    
  </div>
</main>
</body>
</html>
