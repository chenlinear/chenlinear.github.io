<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>programming on Chen Li</title><link>https://ChenLi2049.github.io/tags/programming/</link><description>Recent content in programming on Chen Li</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 10 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://ChenLi2049.github.io/tags/programming/atom.xml" rel="self" type="application/rss+xml"/><item><title>1.58</title><link>https://ChenLi2049.github.io/posts/20240710-1-58/</link><pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20240710-1-58/</guid><description>Sabine mentioned today that the &amp;ldquo;dimension&amp;rdquo; of fractal is $log{(\frac{3}{2})} \approx 1.58$, which reminds me about this LLM quantization method called BitNet with ternary {-1, 0, 1} parameter thus 1.58 bit. I would assume the only connection here is just the number.</description></item><item><title>Local Minimum</title><link>https://ChenLi2049.github.io/posts/20240519-local-minimum/</link><pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20240519-local-minimum/</guid><description>Finding a university for PhD and finding an apartment are both about finding the local minimum, which is that one university/apartment that could work. On the contrary, OpenAI is having an obvious bottleneck right now with the recently released not-so-good product and employees&amp;rsquo; leaving. But I assume their struggle is much more fun, because they are finding the global minimum.
When stuck in a local minimum in Machine Learning, the thing to do is to increase the learning rate and get pass it.</description></item><item><title>Holocene</title><link>https://ChenLi2049.github.io/posts/20240515-holocene/</link><pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20240515-holocene/</guid><description>Replika is an AI girlfriend released in November 2017. One really bizarre thing is that it will recommend &amp;ldquo;Holocene&amp;rdquo; to everyone, similar to how chatGPT recommend &amp;ldquo;delve&amp;rdquo; to everyone. For both of these situations, the bias of the dataset have demonstrated its power over and over again. This is a comment in the comment section of Bon Iver - Holocene:
Our replikas: Listen to this song
Me: Ok
Everybody here: OUR REPLIKAS GATHERED US HERE</description></item><item><title>Minecraft &amp; Programming</title><link>https://ChenLi2049.github.io/posts/20231220-minecraft-programming/</link><pubDate>Wed, 20 Dec 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20231220-minecraft-programming/</guid><description>These are probably trivial but important experiences to me:
Go on mcbbs (a website taken down forever now) for mods, modpacks, texture packs, saves and skins is simular to go on GitHub. Update for Minecraft versions is simular to update for Python versions. In Minecraft, 1.8 -&amp;gt; 1.9 is painful. In Python, 2.x -&amp;gt; 3.x is painful. In Minecraft, 64 is the number in a set of items. In PyTorch, we also use $2^n$.</description></item><item><title>Machine Learning Notes: Maximum Likelihood, Cross Entropy</title><link>https://ChenLi2049.github.io/posts/20231219-machine-learning-notes-maximum-likelihood-cross-entropy/</link><pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20231219-machine-learning-notes-maximum-likelihood-cross-entropy/</guid><description>Maximum Likelihood Estimation: We have a model with parameters $\theta$ and a collection of data examples $X$, the probability of all the examples is the product of each probability:$$L(\theta)=\prod_{i=1}^{n} P_i(\theta; X_i) \tag{1}$$Then we choose the best parameters $\theta$ to maximize $L$.
Â§1 Examples Â§1.1 Coin Flip Consider flipping an unfair coin: In 10 flips $X$, there are 7 heads and 3 tails. Say the probability of head for a single flip is $\theta$, then the probability that this 10 flips happen in this way is $$L(\theta)=\theta^7 (1-\theta)^3 \tag{2}$$.</description></item><item><title>Machine Learning Notes: einops</title><link>https://ChenLi2049.github.io/posts/20231218-machine-learning-notes-einops/</link><pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20231218-machine-learning-notes-einops/</guid><description>Frankly speaking, when I saw Einstein notation in Classical Mechanics, I&amp;rsquo;m not used to it, especially when it&amp;rsquo;s not explicitly said in the context that Einstein notation is used here. I just feel like we can save the trouble by writing more $\sum$.
Anyway, einops do the following things right:
Notation: output_tensor = rearrange(input_tensor, 't b c -&amp;gt; b c t') API: provide package-specific APIs, e.g. torch, tensorflow, jax. There are more and more similar packages:</description></item><item><title>Machine Learning Notes: RNN, LSTM, GRU, RWKV</title><link>https://ChenLi2049.github.io/posts/20231217-machine-learning-notes-rnn-lstm-gru-rwkv/</link><pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20231217-machine-learning-notes-rnn-lstm-gru-rwkv/</guid><description>&amp;ldquo;Recurrent&amp;rdquo; means that, hidden state $h_t$ is a function of the current input $x_t$ and the last hidden state $h_{t-1}$:$$h_t=f(x_t, h_{t-1}; \theta)$$where $\theta$ is all the trainable parameters. We iterate over each word (sub-word) in the entire sequence.
Â§1 RNN nn.RNNCell, nn.RNN
RNN (or vanilla RNN) is composed of 2 Linear layers and an activation function: $$h_t = \tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})$$
Note that in the figure below each square represents the same parameters.</description></item><item><title>Wow It Fits! â€” Secondhand Machine Learning</title><link>https://ChenLi2049.github.io/posts/20231011-wow-it-fits-secondhand-machine-learning/</link><pubDate>Wed, 11 Oct 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20231011-wow-it-fits-secondhand-machine-learning/</guid><description>(There are a lot of pictures so it might take a while to load. This article is actually longer than it looks, because I use tabsets a lot.)
Â§1 Intro This section is about tensor (high-dimensional matrix) and torch.nn.
Â§1.1 Tensor In the rest of the article, we will always:
import torch import torch.nn as nn import torch.nn.functional as F from torchinfo import summary Â§1.1.1 Shape e.g. [H, W, C] (usually used inÂ numpyÂ orÂ matplotlib.</description></item><item><title>Safety Issue of Metaverse</title><link>https://ChenLi2049.github.io/posts/20230929-safety-issue-of-metaverse/</link><pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230929-safety-issue-of-metaverse/</guid><description>In this interview about Metaverse, Lex does not mention safety issue, not even once. I understand how exciting he must be to cross the uncanny valley, but this is highly unprofessional and the interview is approximately a commercial.
I don&amp;rsquo;t think I have to stress how absurd this is:
Scanning your head, more in detail. Because they &amp;ldquo;want to capture your facial expressions&amp;rdquo;. Scanning your house (possibly your family and friends).</description></item><item><title>Machine Learning Notes: A Hackers' Guide to Language Models</title><link>https://ChenLi2049.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</link><pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</guid><description>Jeremy Howard put a video on YouTube about LLMs: A Hackers&amp;rsquo; Guide to Language Models - YouTube, and the GitHub link is lm-hackers. I would watch it again if I were to do the research on LLMs.
The level of detail in this video is amazing. And by &amp;ldquo;the level of detail&amp;rdquo;, I mean
Python code that teaches ChatGPT to run a Python function. Which is powerful, quite handy and embarrassingly simple1.</description></item><item><title>Google Podcasts Shuts Down</title><link>https://ChenLi2049.github.io/posts/20230927-google-podcasts-shuts-down/</link><pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230927-google-podcasts-shuts-down/</guid><description>Another gravestone on Google Graveyard.
Technically it&amp;rsquo;s not shut down, it&amp;rsquo;s gonna be integrated with YouTube Music. So after YouTube Shorts, which is similar to TikTok, YouTube will start promoting music services now. Instead of using that, I&amp;rsquo;m starting to go through open source podcast apps on GitHub.
Since you can also subscribe things on Google Podcasts with RSS, I consider its shut down the splash of Google Reader&amp;rsquo;s death. This sentence from Wikipedia page about Google Reader is ironic:</description></item><item><title>Machine Learning Notes: GNN, GraphNeT</title><link>https://ChenLi2049.github.io/posts/20230910-machine-learning-notes-gnn-graphnet/</link><pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230910-machine-learning-notes-gnn-graphnet/</guid><description>Â§1 Graph A graph is a data structure that has the shape $\mathbb{R} ^{N \times P}$, where
$N$ is the number of nodes. Note that $N$ might vary in a dataset, but we often use cutting or padding to get a uniform, normalized $N$. $P$ is the number of features. Yes, the concept of &amp;ldquo;features&amp;rdquo; is similar to the concept of &amp;ldquo;channels&amp;rdquo; in CNNs. A picture $\mathbb{R}^{H \times W \times C}$ is of height $H$ and width $W$, thus the total number of pixels is $HW$, and each pixel has $C$ channels, commonly $C=1$ (grep channel) or $C=3$ (RGB channels).</description></item><item><title>Machine Learning Notes: Mojonization</title><link>https://ChenLi2049.github.io/posts/20230909-machine-learning-notes-mojonization/</link><pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230909-machine-learning-notes-mojonization/</guid><description>mojonization: n. the migration and translation from Python to Mojo, the superset of Python. (Yeah I made up this word, as far as I know. CrossÂ Mojonization is a totally different thing.)
Python is pesdo-code that works, and Mojo is pesdo-code that works high performantly.
This article summarizes this process and is my notes / cheat sheet. Note that Mojo is relatively new and some rules might be changing rapidly, thus this article can be outdated easily.</description></item><item><title>Machine Learning Notes: Jupyter Notebook 7, Torch 2.0, Mojo Locally</title><link>https://ChenLi2049.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</link><pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</guid><description>It&amp;rsquo;s wild all of these are happening so fast!
On my local computer:
I updated Jupyter Notebook to v7.0.3, and my post Conda 101 is updated. On the server:
CUDA version is now 11.7 and reaches the minimum requirement of torch 2.0. Mojo can be installed locally now, see Mojo ğŸ”¥Â available for local download! Just imagine the speed! Installing process is gonna be hell, but I&amp;rsquo;m ready to go.</description></item><item><title>Machine Learning Notes: Mojo</title><link>https://ChenLi2049.github.io/posts/20230721-machine-learning-notes-mojo/</link><pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230721-machine-learning-notes-mojo/</guid><description>MojoğŸ”¥ is magic. Check out this interview with the founder of Mojo: Chris Lattner: Future of Programming and AI | Lex Fridman Podcast #381 - YouTube. Integrated with python and using multiple CPU/GPU/TPU is unbelievable.
I think the name is actually kinda cool. Though I&amp;rsquo;m sure when it&amp;rsquo;s released (fingers crossed), someone will fork it and name it Dojo, or Casa, or House.1
Starting from 8 Sep 2023, it&amp;rsquo;s available for local download!</description></item><item><title>Machine Learning Notes: fastai</title><link>https://ChenLi2049.github.io/posts/20230706-machine-learning-notes-fastai/</link><pubDate>Thu, 06 Jul 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230706-machine-learning-notes-fastai/</guid><description>(Please refer to Wow It Fits! â€” Secondhand Machine Learning.)
Compared with tensorflow, mxnet, paddle or pure numpy (just for the fun of it), torch is probably the easiest Machine Learning package, and to get it even easier, let&amp;rsquo;s take a look at fastai.
By the way, I subscribed GitHub Trending by RSS and the other day I got these two at the same time. Machine Learning in numpy is really cool, but the second one is like, why?</description></item><item><title>Machine Learning Notes: Workflow &amp; Tips</title><link>https://ChenLi2049.github.io/posts/20230701-machine-learning-notes-workflow-tips/</link><pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230701-machine-learning-notes-workflow-tips/</guid><description>(Please refer to Wow It Fits! â€” Secondhand Machine Learning.)
Here are my notes from Zero to Mastery Learn PyTorch for Deep Learning. For cheatsheet, see PyTorch Cheatsheet - Zero to Mastery Learn PyTorch for Deep Learning or Create a training/testing loop or PyTorch documentation.
Â§1 Workflow Most of the time it&amp;rsquo;s necessary to subclass the classes mentioned above, check PyTorch documentation.
Â§2 Tensor Error See The Three Most Common Errors in PyTorch - Zero to Mastery Learn PyTorch for Deep Learning.</description></item><item><title>Machine Learning Notes: Vision Transformer (ViT)</title><link>https://ChenLi2049.github.io/posts/20230624-machine-learning-notes-vision-transformer/</link><pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230624-machine-learning-notes-vision-transformer/</guid><description>(Please refer to Wow It Fits! â€” Secondhand Machine Learning. There are a lot of pictures in this post so it might take a while to load.)
Original paper is [2010.11929] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Here&amp;rsquo;s some notes from 08. PyTorch Paper Replicating - Zero to Mastery Learn PyTorch for Deep Learning.
The relation between this structure and the equations:
First import packages:</description></item><item><title>Machine Learning Notes: Attention Please</title><link>https://ChenLi2049.github.io/posts/20230615-machine-learning-notes-transformer/</link><pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230615-machine-learning-notes-transformer/</guid><description>(Please refer to Wow It Fits! â€” Secondhand Machine Learning.)
This is my notes from [1706.03762] Attention Is All You Need and The Annotated Transformer and The Illustrated Transformer. This is an outline, I&amp;rsquo;m trying to keep it as simple as possible. You can import these layers and blocks from torch.nn, see Transformer Layers. And I will focus more on structure rather than code itself, because building this model on torch.</description></item><item><title>Machine Learning Notes: torch.nn</title><link>https://ChenLi2049.github.io/posts/20230614-machine-learning-notes-torch-nn/</link><pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230614-machine-learning-notes-torch-nn/</guid><description>(Please refer to Wow It Fits! â€” Secondhand Machine Learning.)
This is a quick introduction to torch or how to build a neural network without writing the source code. For the purpose of each layer, see torch.nn and Dive into Deep Learning. Basically, after CNN, parts of the picture is highlighted and the number of channels (RGB $\rightarrow$ many more) can be different (see CNN Explainer).
In the following code, first import the required packages:</description></item><item><title>Contamination of LLM</title><link>https://ChenLi2049.github.io/posts/20230613-contamination-of-llm/</link><pubDate>Tue, 13 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230613-contamination-of-llm/</guid><description>This is the dark side of the Force.
In one of my previous posts, I talked about Ted Chiang&amp;rsquo;s idea on LLMs. At that time his idea only seems plausible, but now that more papers are published, I want to talk about how LLMs are contaminating the source material.
Training LLM with LLM-produced material will produce terrible results.1 This is $\text{Ted Chiang&amp;rsquo;s idea}^n$.
And the contamination can be divided into two parts in general:</description></item><item><title>immersive-translate</title><link>https://ChenLi2049.github.io/posts/20230602-immersive-translate/</link><pubDate>Fri, 02 Jun 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230602-immersive-translate/</guid><description>immersive-translate is a great translating extension, which has a nice format, can open .epub file and translate .epub file directly.
There&amp;rsquo;s a bug, when translating Feedly, the translated content in the side bar would convert with the original content. According to é«˜çº§è‡ªå®šä¹‰é…ç½®, I used:
[ { &amp;#34;matches&amp;#34;: &amp;#34;feedly.com&amp;#34;, &amp;#34;excludeSelectors&amp;#34;: [ &amp;#34;nav&amp;#34;, &amp;#34;footer&amp;#34; ] } ] Learning a little html is really useful.
For the translation box, I used purple quotation-style.</description></item><item><title>LaTeX Style</title><link>https://ChenLi2049.github.io/posts/20230521-latex-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230521-latex-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
But I&amp;rsquo;d like to say TinyTeX (~500 MB) or Overleaf (0 MB) are better choices than TeX Live (~5 GB). I normally write in Markdown first, and then use Overleaf. If you&amp;rsquo;re using JupyterLab, jupyterlab-latex is basically the local version of Overleaf.
Â§1 General About the name: $\LaTeX$ ($\LaTeX$) is great, LaTeX or latex is acceptable, lAtEx is brutal.</description></item><item><title>Markdown Style</title><link>https://ChenLi2049.github.io/posts/20230521-markdown-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230521-markdown-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
Obsidian is the text editor that I&amp;rsquo;m using. I like workspaces and double link feature.
Â§1 General Markdown Guide is good as a quick introduction.
The thing about Markdown style is that every text editor has its own accent. I suggest using the universal ones, not the ones that a certain text editor created.</description></item><item><title>Python Style</title><link>https://ChenLi2049.github.io/posts/20230521-python-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230521-python-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
But I&amp;rsquo;d like to say Anaconda is a better choice than just Python itself. You can manage different packages in different environments with Anaconda.
This article is about what I find interesting in PEP 8 â€“ Style Guide for Python Code1, PEP 257 â€“ Docstring Conventions, Style guide â€” numpydoc v1.</description></item><item><title>New Repository: PEP-8-ZH</title><link>https://ChenLi2049.github.io/posts/20230520-new-repository-pep-8-zh/</link><pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230520-new-repository-pep-8-zh/</guid><description>I created a repository called PEP-8-ZH. Basically, I translated PEP 8 with the help of ChatGPT, and with a little modification myself. The prompt that I use is:
å°†ä¸‹æ–‡ç¿»è¯‘ä¸ºä¸­æ–‡ And I did not translate the comments, because you should try to write comments in English.
If you want to learn about Python style, I recommend Google Style Guides (ä¸­æ–‡ç‰ˆè§ Google å¼€æºé¡¹ç›®é£æ ¼æŒ‡å—) as the guide. Which is more up to date. I&amp;rsquo;ll write about Python style soon.</description></item><item><title>List of a Folder</title><link>https://ChenLi2049.github.io/posts/20230423-list-of-a-folder/</link><pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230423-list-of-a-folder/</guid><description>Â§1 path In Windows, to get the list of all the files in a folder:
Create a .txt file.
Open it with notepad. Copy and paste the following commands:
@echo off dir %1 /s/b &amp;gt; %~n1.txt Or, if you don&amp;rsquo;t want the list of what&amp;rsquo;s in the subdirectory:
@echo off dir %1 /b &amp;gt; %~n1.txt Rename it getList.bat (&amp;ldquo;getList&amp;rdquo; could be anything.)
Drag the target folder to this .bat file.</description></item><item><title>New Repository: DrSlidelove</title><link>https://ChenLi2049.github.io/posts/20230423-new-repository-slidy/</link><pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230423-new-repository-slidy/</guid><description>Update 20230617: I&amp;rsquo;m so sorry that there&amp;rsquo;s already aÂ Slidy. When I used that name for this repository, there&amp;rsquo;s no such a repository named Slidy and I thought it would be ok. To avoid any confusion, the name is changed from Slidy to DrSlidelove. Again, my apologies.
I just created a new repository for slide, which is called Slidy. Well, technically I didn&amp;rsquo;t create it, I just moved stuff around.</description></item><item><title>Conda 101</title><link>https://ChenLi2049.github.io/posts/20230327-conda-101/</link><pubDate>Mon, 27 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230327-conda-101/</guid><description>This article is a quick guidance to use Anaconda &amp;amp; Miniconda on Windows. I wrote it so that I can check the command myself. Sorry about other platforms such as Linux, WSL on Windows or MacOS, but the Â§2 should be useful too.
Â§1 Anaconda Go the the official website Anaconda and download the default exe file. Open and install it. Get familiar with Jupyter Notebook. Feel free to check out some other articles and mess around, knowing that you can always delete the old environment and start from scratch, you&amp;rsquo;ll be fine.</description></item><item><title>Robin</title><link>https://ChenLi2049.github.io/posts/20230321-robin/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230321-robin/</guid><description>Besides writing code, having ChatGPT pretend to be Robin from How I Met Your Mother and engaging in a conversation with her is so funny. She is constantly making things up and I am trying my best to make the story work. And when it does, it&amp;rsquo;s amazing!
It&amp;rsquo;s even more fun to ask ChatGPT to be Jamie Lannister, since there is (part of) a whole novel and countless online discussions.</description></item><item><title>RSS: Why and How?</title><link>https://ChenLi2049.github.io/posts/20230304-rss-why-and-how/</link><pubDate>Sat, 04 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230304-rss-why-and-how/</guid><description>RSS, personal website and the word &amp;ldquo;neat&amp;rdquo; shared a lot in common, one of which is that they died out at the beginning of this century but have become more useful ever since.
Â§1 Why? The whole goal of RSS is to keep it simple. I don&amp;rsquo;t want to check a lot of websites over and over again. Something should be read and then forgotten, unless it&amp;rsquo;s important, in which case I will mark it down.</description></item><item><title>å¯’æ­¦çºª MLU370-X4 å®‰è£…åœ¨æœ¬åœ°æœåŠ¡å™¨çš„ ubuntu ä¸Š</title><link>https://ChenLi2049.github.io/posts/20230304-gpu-dock/</link><pubDate>Sat, 04 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230304-gpu-dock/</guid><description>è¿˜æœªç»æµ‹è¯•!
æ˜¾å¡ï¼šå¯’æ­¦çºª MLU370-X4ã€‚
æ˜¾å¡åçš„è§£å†³æ–¹å¼ææ€•ä¸è¡Œï¼Œå› ä¸ºå¦‚æœé‡æ–°æ›´æ¢è®¾å¤‡éœ€è¦é‡æ–°ä» ubuntu å¼€å§‹è£…èµ·ï¼Œä¸å¦‚åœ¨å¦ä¸€å°æœºå™¨ä¸Šæ„å»ºä¸€ä¸ªæœ¬åœ°æœåŠ¡å™¨ã€‚é™¤æ­¤ä¹‹å¤–çš„é—®é¢˜è¿˜æœ‰ï¼šç¬”è®°æœ¬è‡ªå¸¦çš„æ ¸æ˜¾ä¼šæ‰“æ¶å—ï¼Ÿç¡¬ç›˜å®¹é‡ä¸å¤Ÿäº†ã€‚:(
è§†é¢‘ä»‹ç»ï¼ˆé™¤3.å‡ ä¹å®Œå…¨æ˜¯è¿™ä¸ªçŸ¥ä¹ä¸“æ çš„å†…å®¹ï¼‰ï¼š
å¯’æ­¦çºª MLU370 åŠ é€Ÿå¡ç®€ä»‹åŠå®‰è£… å¯’æ­¦çºªåŸºç¡€è½¯ä»¶å¹³å°å®‰è£… MLU370 å¼€å‘å®æˆ˜ æ–‡æ¡£ï¼ˆåœ¨ç†Ÿæ‚‰è§†é¢‘ä»‹ç»ä¹‹åå†æŸ¥çœ‹ï¼‰ï¼š
æ–‡æ¡£ä¸­å¿ƒ MLU370-X4 æ™ºèƒ½åŠ é€Ÿå¡äº§å“æ‰‹å†Œ 1.0.0 æ–‡æ¡£ æˆ‘è®¾æƒ³çš„æœ¬åœ°æœåŠ¡å™¨çš„æ„å»ºæµç¨‹ï¼š
å®‰è£… ubuntuï¼Œç‰ˆæœ¬å·è§è§†é¢‘ä»‹ç»ï¼š16.04æˆ–18.04? æŒ‰ç…§è§†é¢‘ä»‹ç»å®‰è£… torch.mlu ç»„ä»¶ç­‰ç­‰ï¼ˆå’Œ Dive into Deep Learning1 è¿™æœ¬ä¹¦ä¸åŒçš„åœ°æ–¹åœ¨äºï¼Œå¯’æ­¦çºªåœ¨ä½¿ç”¨ pytorch æ—¶å¯¼å…¥ torch å’Œ torch.mlu å³å¯ï¼Œä¸éœ€å®‰è£… torchvision å³ pytorch çš„ GPU ç‰ˆæœ¬ï¼Œæ­¤å¤„ mlu å’Œ gpu æ˜¯ä¸¤ä¸ªç›¸å¯¹çš„æ¦‚å¿µï¼ŒæŒ‡è°ƒç”¨çš„åº•å±‚æ¶æ„ä¸åŒï¼‰ å®‰è£… JupyterNotebookã€‚ å°è¯•å¯’æ­¦çºªå¼€å‘çš„å·¥å…· MagicMind å’Œ YOLOv5ã€‚è§ Cambricon(gitee.com)ã€‚ å¦ä¸€æœ¬å¾ˆæ¨èçš„ä¹¦æ˜¯ã€Šæ™ºèƒ½è®¡ç®—ç³»ç»Ÿã€‹&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Hello World</title><link>https://ChenLi2049.github.io/posts/20230303-hello-world/</link><pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate><guid>https://ChenLi2049.github.io/posts/20230303-hello-world/</guid><description>Hello World!</description></item></channel></rss>