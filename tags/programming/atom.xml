<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>programming on Chen Li</title><link>https://chenlinear.github.io/tags/programming/</link><description>Recent content in programming on Chen Li</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 10 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://chenlinear.github.io/tags/programming/atom.xml" rel="self" type="application/rss+xml"/><item><title>1.58</title><link>https://chenlinear.github.io/posts/20240710-1-58/</link><pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20240710-1-58/</guid><description>Sabine mentioned today that the &amp;ldquo;dimension&amp;rdquo; of fractal is $log{(\frac{3}{2})} \approx 1.58$, which reminds me about this LLM quantization method called BitNet with ternary {-1, 0, 1} parameter thus 1.58 bit. I would assume the only connection here is just the number.</description></item><item><title>Local Minimum</title><link>https://chenlinear.github.io/posts/20240519-local-minimum/</link><pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20240519-local-minimum/</guid><description>Finding a university for PhD and finding an apartment are both about finding the local minimum, which is that one university/apartment that could work. On the contrary, OpenAI is having an obvious bottleneck right now with the recently released not-so-good product and employees&amp;rsquo; leaving. But I assume their struggle is much more fun, because they are finding the global minimum.
When stuck in a local minimum in Machine Learning, the thing to do is to increase the learning rate and get pass it.</description></item><item><title>Holocene</title><link>https://chenlinear.github.io/posts/20240515-holocene/</link><pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20240515-holocene/</guid><description>Replika is an AI girlfriend released in November 2017. One really bizarre thing is that it will recommend &amp;ldquo;Holocene&amp;rdquo; to everyone, similar to how chatGPT recommend &amp;ldquo;delve&amp;rdquo; to everyone. For both of these situations, the bias of the dataset have demonstrated its power over and over again. This is a comment in the comment section of Bon Iver - Holocene:
Our replikas: Listen to this song
Me: Ok
Everybody here: OUR REPLIKAS GATHERED US HERE</description></item><item><title>Minecraft &amp; Programming</title><link>https://chenlinear.github.io/posts/20231220-minecraft-programming/</link><pubDate>Wed, 20 Dec 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20231220-minecraft-programming/</guid><description>These are probably trivial but important experiences to me:
Go on mcbbs (a website taken down forever now) for mods, modpacks, texture packs, saves and skins is simular to go on GitHub. Update for Minecraft versions is simular to update for Python versions. In Minecraft, 1.8 -&amp;gt; 1.9 is painful. In Python, 2.x -&amp;gt; 3.x is painful. In Minecraft, 64 is the number in a set of items. In PyTorch, we also use $2^n$.</description></item><item><title>Machine Learning Notes: Maximum Likelihood, Cross Entropy</title><link>https://chenlinear.github.io/posts/20231219-machine-learning-notes-maximum-likelihood-cross-entropy/</link><pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20231219-machine-learning-notes-maximum-likelihood-cross-entropy/</guid><description>Maximum Likelihood Estimation: We have a model with parameters $\theta$ and a collection of data examples $X$, the probability of all the examples is the product of each probability:$$L(\theta)=\prod_{i=1}^{n} P_i(\theta; X_i) \tag{1}$$Then we choose the best parameters $\theta$ to maximize $L$.
§1 Examples §1.1 Coin Flip Consider flipping an unfair coin: In 10 flips $X$, there are 7 heads and 3 tails. Say the probability of head for a single flip is $\theta$, then the probability that this 10 flips happen in this way is $$L(\theta)=\theta^7 (1-\theta)^3 \tag{2}$$.</description></item><item><title>Machine Learning Notes: einops</title><link>https://chenlinear.github.io/posts/20231218-machine-learning-notes-einops/</link><pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20231218-machine-learning-notes-einops/</guid><description>Frankly speaking, when I saw Einstein notation in Classical Mechanics, I&amp;rsquo;m not used to it, especially when it&amp;rsquo;s not explicitly said in the context that Einstein notation is used here. I just feel like we can save the trouble by writing more $\sum$.
Anyway, einops do the following things right:
Notation: output_tensor = rearrange(input_tensor, 't b c -&amp;gt; b c t') API: provide package-specific APIs, e.g. torch, tensorflow, jax. There are more and more similar packages:</description></item><item><title>Machine Learning Notes: RNN, LSTM, GRU, RWKV</title><link>https://chenlinear.github.io/posts/20231217-machine-learning-notes-rnn-lstm-gru-rwkv/</link><pubDate>Sun, 17 Dec 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20231217-machine-learning-notes-rnn-lstm-gru-rwkv/</guid><description>&amp;ldquo;Recurrent&amp;rdquo; means that, hidden state $h_t$ is a function of the current input $x_t$ and the last hidden state $h_{t-1}$:$$h_t=f(x_t, h_{t-1}; \theta)$$where $\theta$ is all the trainable parameters. We iterate over each word (sub-word) in the entire sequence.
§1 RNN nn.RNNCell, nn.RNN
RNN (or vanilla RNN) is composed of 2 Linear layers and an activation function: $$h_t = \tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})$$
Note that in the figure below each square represents the same parameters.</description></item><item><title>Wow It Fits! — Secondhand Machine Learning</title><link>https://chenlinear.github.io/posts/20231011-wow-it-fits-secondhand-machine-learning/</link><pubDate>Wed, 11 Oct 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20231011-wow-it-fits-secondhand-machine-learning/</guid><description>(There are a lot of pictures so it might take a while to load. This article is actually longer than it looks, because I use tabsets a lot.)
§1 Intro This section is about tensor (high-dimensional matrix) and torch.nn.
§1.1 Tensor In the rest of the article, we will always:
import torch import torch.nn as nn import torch.nn.functional as F from torchinfo import summary §1.1.1 Shape e.g. [H, W, C] (usually used in numpy or matplotlib.</description></item><item><title>Safety Issue of Metaverse</title><link>https://chenlinear.github.io/posts/20230929-safety-issue-of-metaverse/</link><pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230929-safety-issue-of-metaverse/</guid><description>In this interview about Metaverse, Lex does not mention safety issue, not even once. I understand how exciting he must be to cross the uncanny valley, but this is highly unprofessional and the interview is approximately a commercial.
I don&amp;rsquo;t think I have to stress how absurd this is:
Scanning your head, more in detail. Because they &amp;ldquo;want to capture your facial expressions&amp;rdquo;. Scanning your house (possibly your family and friends).</description></item><item><title>Machine Learning Notes: A Hackers' Guide to Language Models</title><link>https://chenlinear.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</link><pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230928-machine-learning-notes-a-hackers-guide-to-language-models/</guid><description>Jeremy Howard put a video on YouTube about LLMs: A Hackers&amp;rsquo; Guide to Language Models - YouTube, and the GitHub link is lm-hackers. I would watch it again if I were to do the research on LLMs.
The level of detail in this video is amazing. And by &amp;ldquo;the level of detail&amp;rdquo;, I mean
Python code that teaches ChatGPT to run a Python function. Which is powerful, quite handy and embarrassingly simple1.</description></item><item><title>Google Podcasts Shuts Down</title><link>https://chenlinear.github.io/posts/20230927-google-podcasts-shuts-down/</link><pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230927-google-podcasts-shuts-down/</guid><description>Another gravestone on Google Graveyard.
Technically it&amp;rsquo;s not shut down, it&amp;rsquo;s gonna be integrated with YouTube Music. So after YouTube Shorts, which is similar to TikTok, YouTube will start promoting music services now. Instead of using that, I&amp;rsquo;m starting to go through open source podcast apps on GitHub.
Since you can also subscribe things on Google Podcasts with RSS, I consider its shut down the splash of Google Reader&amp;rsquo;s death. This sentence from Wikipedia page about Google Reader is ironic:</description></item><item><title>Machine Learning Notes: GNN, GraphNeT</title><link>https://chenlinear.github.io/posts/20230910-machine-learning-notes-gnn-graphnet/</link><pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230910-machine-learning-notes-gnn-graphnet/</guid><description>§1 Graph A graph is a data structure that has the shape $\mathbb{R} ^{N \times P}$, where
$N$ is the number of nodes. Note that $N$ might vary in a dataset, but we often use cutting or padding to get a uniform, normalized $N$. $P$ is the number of features. Yes, the concept of &amp;ldquo;features&amp;rdquo; is similar to the concept of &amp;ldquo;channels&amp;rdquo; in CNNs. A picture $\mathbb{R}^{H \times W \times C}$ is of height $H$ and width $W$, thus the total number of pixels is $HW$, and each pixel has $C$ channels, commonly $C=1$ (grey channel) or $C=3$ (RGB channels).</description></item><item><title>Machine Learning Notes: Mojonization</title><link>https://chenlinear.github.io/posts/20230909-machine-learning-notes-mojonization/</link><pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230909-machine-learning-notes-mojonization/</guid><description>mojonization: n. the migration and translation from Python to Mojo, the superset of Python. (Yeah I made up this word, as far as I know. Cross Mojonization is a totally different thing.)
Python is pesdo-code that works, and Mojo is pesdo-code that works high performantly.
This article summarizes this process and is my notes / cheat sheet. Note that Mojo is relatively new and some rules might be changing rapidly, thus this article can be outdated easily.</description></item><item><title>Machine Learning Notes: Jupyter Notebook 7, Torch 2.0, Mojo Locally</title><link>https://chenlinear.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</link><pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230908-machine-learning-notes-jupyter-notebook-7-torch-20-mojo-locally/</guid><description>It&amp;rsquo;s wild all of these are happening so fast!
On my local computer:
I updated Jupyter Notebook to v7.0.3, and my post Conda 101 is updated. On the server:
CUDA version is now 11.7 and reaches the minimum requirement of torch 2.0. Mojo can be installed locally now, see Mojo 🔥 available for local download! Just imagine the speed! Installing process is gonna be hell, but I&amp;rsquo;m ready to go.</description></item><item><title>Machine Learning Notes: Mojo</title><link>https://chenlinear.github.io/posts/20230721-machine-learning-notes-mojo/</link><pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230721-machine-learning-notes-mojo/</guid><description>Mojo🔥 is magic. Check out this interview with the founder of Mojo: Chris Lattner: Future of Programming and AI | Lex Fridman Podcast #381 - YouTube. Integrated with python and using multiple CPU/GPU/TPU is unbelievable.
I think the name is actually kinda cool. Though I&amp;rsquo;m sure when it&amp;rsquo;s released (fingers crossed), someone will fork it and name it Dojo, or Casa, or House.1
Starting from 8 Sep 2023, it&amp;rsquo;s available for local download!</description></item><item><title>Machine Learning Notes: fastai</title><link>https://chenlinear.github.io/posts/20230706-machine-learning-notes-fastai/</link><pubDate>Thu, 06 Jul 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230706-machine-learning-notes-fastai/</guid><description>(Please refer to Wow It Fits! — Secondhand Machine Learning.)
Compared with tensorflow, mxnet, paddle or pure numpy (just for the fun of it), torch is probably the easiest Machine Learning package, and to get it even easier, let&amp;rsquo;s take a look at fastai.
By the way, I subscribed GitHub Trending by RSS and the other day I got these two at the same time. Machine Learning in numpy is really cool, but the second one is like, why?</description></item><item><title>Machine Learning Notes: Workflow &amp; Tips</title><link>https://chenlinear.github.io/posts/20230701-machine-learning-notes-workflow-tips/</link><pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230701-machine-learning-notes-workflow-tips/</guid><description>(Please refer to Wow It Fits! — Secondhand Machine Learning.)
Here are my notes from Zero to Mastery Learn PyTorch for Deep Learning. For cheatsheet, see PyTorch Cheatsheet - Zero to Mastery Learn PyTorch for Deep Learning or Create a training/testing loop or PyTorch documentation.
§1 Workflow Most of the time it&amp;rsquo;s necessary to subclass the classes mentioned above, check PyTorch documentation.
§2 Tensor Error See The Three Most Common Errors in PyTorch - Zero to Mastery Learn PyTorch for Deep Learning.</description></item><item><title>Machine Learning Notes: Vision Transformer (ViT)</title><link>https://chenlinear.github.io/posts/20230624-machine-learning-notes-vision-transformer/</link><pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230624-machine-learning-notes-vision-transformer/</guid><description>(Please refer to Wow It Fits! — Secondhand Machine Learning. There are a lot of pictures in this post so it might take a while to load.)
Original paper is [2010.11929] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Here&amp;rsquo;s some notes from 08. PyTorch Paper Replicating - Zero to Mastery Learn PyTorch for Deep Learning.
The relation between this structure and the equations:
First import packages:</description></item><item><title>Machine Learning Notes: Attention Please</title><link>https://chenlinear.github.io/posts/20230615-machine-learning-notes-transformer/</link><pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230615-machine-learning-notes-transformer/</guid><description>(Please refer to Wow It Fits! — Secondhand Machine Learning.)
This is my notes from [1706.03762] Attention Is All You Need and The Annotated Transformer and The Illustrated Transformer. This is an outline, I&amp;rsquo;m trying to keep it as simple as possible. You can import these layers and blocks from torch.nn, see Transformer Layers. And I will focus more on structure rather than code itself, because building this model on torch.</description></item><item><title>Machine Learning Notes: torch.nn</title><link>https://chenlinear.github.io/posts/20230614-machine-learning-notes-torch-nn/</link><pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230614-machine-learning-notes-torch-nn/</guid><description>(Please refer to Wow It Fits! — Secondhand Machine Learning.)
This is a quick introduction to torch or how to build a neural network without writing the source code. For the purpose of each layer, see torch.nn and Dive into Deep Learning. Basically, after CNN, parts of the picture is highlighted and the number of channels (RGB $\rightarrow$ many more) can be different (see CNN Explainer).
In the following code, first import the required packages:</description></item><item><title>Contamination of LLM</title><link>https://chenlinear.github.io/posts/20230613-contamination-of-llm/</link><pubDate>Tue, 13 Jun 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230613-contamination-of-llm/</guid><description>This is the dark side of the Force.
In one of my previous posts, I talked about Ted Chiang&amp;rsquo;s idea on LLMs. At that time his idea only seems plausible, but now that more papers are published, I want to talk about how LLMs are contaminating the source material.
Training LLM with LLM-produced material will produce terrible results.1 This is $\text{Ted Chiang&amp;rsquo;s idea}^n$.
And the contamination can be divided into two parts in general:</description></item><item><title>immersive-translate</title><link>https://chenlinear.github.io/posts/20230602-immersive-translate/</link><pubDate>Fri, 02 Jun 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230602-immersive-translate/</guid><description>immersive-translate is a great translating extension, which has a nice format, can open .epub file and translate .epub file directly.
There&amp;rsquo;s a bug, when translating Feedly, the translated content in the side bar would convert with the original content. According to 高级自定义配置, I used:
[ { &amp;#34;matches&amp;#34;: &amp;#34;feedly.com&amp;#34;, &amp;#34;excludeSelectors&amp;#34;: [ &amp;#34;nav&amp;#34;, &amp;#34;footer&amp;#34; ] } ] Learning a little html is really useful.
For the translation box, I used purple quotation-style.</description></item><item><title>LaTeX Style</title><link>https://chenlinear.github.io/posts/20230521-latex-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230521-latex-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
But I&amp;rsquo;d like to say TinyTeX (~500 MB) or Overleaf (0 MB) are better choices than TeX Live (~5 GB). I normally write in Markdown first, and then use Overleaf. If you&amp;rsquo;re using JupyterLab, jupyterlab-latex is basically the local version of Overleaf.
§1 General About the name: $\LaTeX$ ($\LaTeX$) is great, LaTeX or latex is acceptable, lAtEx is brutal.</description></item><item><title>Markdown Style</title><link>https://chenlinear.github.io/posts/20230521-markdown-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230521-markdown-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
Obsidian is the text editor that I&amp;rsquo;m using. I like workspaces and double link feature.
§1 General Markdown Guide is good as a quick introduction.
The thing about Markdown style is that every text editor has its own accent. I suggest using the universal ones, not the ones that a certain text editor created.</description></item><item><title>Python Style</title><link>https://chenlinear.github.io/posts/20230521-python-style/</link><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230521-python-style/</guid><description>If you don&amp;rsquo;t know what it is, I recommend you should just play with it and don&amp;rsquo;t care about the style.
But I&amp;rsquo;d like to say Anaconda is a better choice than just Python itself. You can manage different packages in different environments with Anaconda.
This article is about what I find interesting in PEP 8 – Style Guide for Python Code1, PEP 257 – Docstring Conventions, Style guide — numpydoc v1.</description></item><item><title>New Repository: PEP-8-ZH</title><link>https://chenlinear.github.io/posts/20230520-new-repository-pep-8-zh/</link><pubDate>Sat, 20 May 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230520-new-repository-pep-8-zh/</guid><description>I created a repository called PEP-8-ZH. Basically, I translated PEP 8 with the help of ChatGPT, and with a little modification myself. The prompt that I use is:
将下文翻译为中文 And I did not translate the comments, because you should try to write comments in English.
If you want to learn about Python style, I recommend Google Style Guides (中文版见 Google 开源项目风格指南) as the guide. Which is more up to date. I&amp;rsquo;ll write about Python style soon.</description></item><item><title>List of a Folder</title><link>https://chenlinear.github.io/posts/20230423-list-of-a-folder/</link><pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230423-list-of-a-folder/</guid><description>§1 path In Windows, to get the list of all the files in a folder:
Create a .txt file.
Open it with notepad. Copy and paste the following commands:
@echo off dir %1 /s/b &amp;gt; %~n1.txt Or, if you don&amp;rsquo;t want the list of what&amp;rsquo;s in the subdirectory:
@echo off dir %1 /b &amp;gt; %~n1.txt Rename it getList.bat (&amp;ldquo;getList&amp;rdquo; could be anything.)
Drag the target folder to this .bat file.</description></item><item><title>New Repository: DrSlidelove</title><link>https://chenlinear.github.io/posts/20230423-new-repository-slidy/</link><pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230423-new-repository-slidy/</guid><description>Update 20230617: I&amp;rsquo;m so sorry that there&amp;rsquo;s already a Slidy. When I used that name for this repository, there&amp;rsquo;s no such a repository named Slidy and I thought it would be ok. To avoid any confusion, the name is changed from Slidy to DrSlidelove. Again, my apologies.
I just created a new repository for slide, which is called Slidy. Well, technically I didn&amp;rsquo;t create it, I just moved stuff around.</description></item><item><title>Conda 101</title><link>https://chenlinear.github.io/posts/20230327-conda-101/</link><pubDate>Mon, 27 Mar 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230327-conda-101/</guid><description>This article is a quick guidance to use Anaconda &amp;amp; Miniconda on Windows and Linux. I wrote it so that I can check the command myself.
§1 Anaconda For Windows: Go the the official website Anaconda and download the default exe file. Open and install it.
Get familiar with Jupyter Notebook. Feel free to check out some other articles and mess around, knowing that you can always delete the old environment and start from scratch, you&amp;rsquo;ll be fine.</description></item><item><title>Robin</title><link>https://chenlinear.github.io/posts/20230321-robin/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230321-robin/</guid><description>Besides writing code, having ChatGPT pretend to be Robin from How I Met Your Mother and engaging in a conversation with her is so funny. She is constantly making things up and I am trying my best to make the story work. And when it does, it&amp;rsquo;s amazing!
It&amp;rsquo;s even more fun to ask ChatGPT to be Jamie Lannister, since there is (part of) a whole novel and countless online discussions.</description></item><item><title>RSS: Why and How?</title><link>https://chenlinear.github.io/posts/20230304-rss-why-and-how/</link><pubDate>Sat, 04 Mar 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230304-rss-why-and-how/</guid><description>RSS, personal website and the word &amp;ldquo;neat&amp;rdquo; shared a lot in common, one of which is that they died out at the beginning of this century but have become more useful ever since.
§1 Why? The whole goal of RSS is to keep it simple. I don&amp;rsquo;t want to check a lot of websites over and over again. Something should be read and then forgotten, unless it&amp;rsquo;s important, in which case I will mark it down.</description></item><item><title>寒武纪 MLU370-X4 安装在本地服务器的 ubuntu 上</title><link>https://chenlinear.github.io/posts/20230304-gpu-dock/</link><pubDate>Sat, 04 Mar 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230304-gpu-dock/</guid><description>还未经测试!
显卡：寒武纪 MLU370-X4。
显卡坞的解决方式恐怕不行，因为如果重新更换设备需要重新从 ubuntu 开始装起，不如在另一台机器上构建一个本地服务器。除此之外的问题还有：笔记本自带的核显会打架吗？硬盘容量不够了。:(
视频介绍（除3.几乎完全是这个知乎专栏的内容）：
寒武纪 MLU370 加速卡简介及安装 寒武纪基础软件平台安装 MLU370 开发实战 文档（在熟悉视频介绍之后再查看）：
文档中心 MLU370-X4 智能加速卡产品手册 1.0.0 文档 我设想的本地服务器的构建流程：
安装 ubuntu，版本号见视频介绍：16.04或18.04? 按照视频介绍安装 torch.mlu 组件等等（和 Dive into Deep Learning1 这本书不同的地方在于，寒武纪在使用 pytorch 时导入 torch 和 torch.mlu 即可，不需安装 torchvision 即 pytorch 的 GPU 版本，此处 mlu 和 gpu 是两个相对的概念，指调用的底层架构不同） 安装 JupyterNotebook。 尝试寒武纪开发的工具 MagicMind 和 YOLOv5。见 Cambricon(gitee.com)。 另一本很推荐的书是《智能计算系统》&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Hello World</title><link>https://chenlinear.github.io/posts/20230303-hello-world/</link><pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate><guid>https://chenlinear.github.io/posts/20230303-hello-world/</guid><description>Hello World!</description></item></channel></rss>